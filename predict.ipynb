{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# The following code is a classification neural network\n",
    "\n",
    "# Import all packages and libraries for NN\n",
    "\n",
    "# from numpy.random import seed\n",
    "# seed(1)\n",
    "# from tensorflow import set_random_seed\n",
    "# set_random_seed(2)\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.utils import shuffle\n",
    "from keras.utils import np_utils\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from numpy import argmax\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "import numpy\n",
    "import keras\n",
    "import pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Processing\n",
    "# Preparing Iris dataset for usage as a dataframe\n",
    "# Encoding output variables\n",
    "# Shuffle rows randomly for variety\n",
    "# Spliting dataset to test and train dataframes. Test dataset will be 80% of entire dataframe.\n",
    "# Parsing dataframe to features and labels (x_train and y_train)\n",
    "\n",
    "# Constants\n",
    "_training_split = 0.8\n",
    "\n",
    "\n",
    "# Spliting dataframe to training and testing\n",
    "def split_to_training(dataframe):\n",
    "    train_df = dataframe[:int(len(dataframe)*_training_split)]\n",
    "    \n",
    "    return train_df\n",
    "\n",
    "\n",
    "def split_to_testing(dataframe):\n",
    "    test_df = dataframe[int(len(dataframe)*_training_split):]\n",
    "    \n",
    "    return test_df\n",
    "\n",
    "\n",
    "# Spliting training or testing dataset to x and y\n",
    "def split_to_x(dataframe):\n",
    "    x = dataframe[features].values\n",
    "    \n",
    "    return x\n",
    "\n",
    "\n",
    "def split_to_y(dataframe):\n",
    "    y = dataframe[labels].values\n",
    "    \n",
    "    return y\n",
    "\n",
    "\n",
    "# Encoding all labels with HOT Encoder\n",
    "def encode_dataframe(label_y):\n",
    "    encoder = LabelEncoder()\n",
    "    encoder.fit(label_y)\n",
    "    encoded_Y = encoder.transform(label_y)\n",
    "    new_y = np_utils.to_categorical(encoded_Y)\n",
    "    \n",
    "    return new_y\n",
    "\n",
    "\n",
    "def prep_data(df):\n",
    "    pass\n",
    "    \n",
    "# Load in dataset\n",
    "dataframe = pandas.read_csv('iris.csv')\n",
    "df = shuffle(dataframe)\n",
    "features = list(df.columns.values)[:-1]\n",
    "labels = list(df.columns.values)[-1]\n",
    "input_dim = len(list(df.columns.values)[:-1])\n",
    "\n",
    "train_df = split_to_training(df)\n",
    "x_train = split_to_x(train_df)\n",
    "y_train = encode_dataframe(split_to_y(train_df))\n",
    "\n",
    "test_df = split_to_testing(df)\n",
    "x_test = split_to_x(test_df)\n",
    "y_test = encode_dataframe(split_to_y(test_df))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KerasNeuralNetwork:\n",
    "    def __init__(self, x_train, y_train, x_test, y_test):\n",
    "        self.x_train = x_train\n",
    "        self.y_train = y_train\n",
    "        self.x_test = x_test\n",
    "        self.y_test = y_test\n",
    "        \n",
    "        \n",
    "    def run(self):\n",
    "        _number_of_test_models = 10\n",
    "        \n",
    "        base_number_layers = int(input_dim**.5)\n",
    "        list_of_loss = []\n",
    "        list_of_models = []\n",
    "        list_of_history = []\n",
    "        for i in range(_number_of_test_models):\n",
    "            model = Sequential()\n",
    "            # Base number of layers\n",
    "            model.add(Dense(input_dim, input_dim=input_dim, activation='sigmoid'))\n",
    "            for i in range(base_number_layers):\n",
    "                model.add(Dense(5, activation='sigmoid'))\n",
    "            model.add(Dense(3, activation='sigmoid'))\n",
    "            model.summary()\n",
    "        \n",
    "            model.compile(loss='mean_absolute_error', optimizer='adam', metrics=['accuracy'])\n",
    "            list_of_models.append(model)\n",
    "\n",
    "            \n",
    "            history = model.fit(self.x_train, self.y_train, epochs=30)\n",
    "            list_of_history.append(history)\n",
    "        \n",
    "        \n",
    "            # Compare loss after each epoch\n",
    "            loss_after_each_epoch = history.history['loss']\n",
    "            avg_roc = abs((loss_after_each_epoch[0]-loss_after_each_epoch[-1])/len(loss_after_each_epoch))\n",
    "            list_of_loss.append(avg_roc)\n",
    "            base_number_layers += 1\n",
    "            \n",
    "            scores = model.evaluate(self.x_test, self.y_test)\n",
    "            print(\"{}: {}\".format(model.metrics_names[0], scores[0]))\n",
    "            print(\"{}: {}%\".format(model.metrics_names[1], scores[1]*100))\n",
    "        \n",
    "        # Take the first trough in list and use that model\n",
    "        minimal_loss_position = 0;\n",
    "        for index, value in enumerate(list_of_loss):\n",
    "            if value < list_of_loss[index+1]:\n",
    "                minimal_loss_position = index\n",
    "                break\n",
    "        print(list_of_loss)\n",
    "        print(list_of_models)\n",
    "        print('The optimal model is at index: {}'.format(minimal_loss_position))\n",
    "        optimized_model = list_of_models[minimal_loss_position]\n",
    "        optimized_history = list_of_history[minimal_loss_position]\n",
    "        \n",
    "        # Evaluating the model\n",
    "        print(optimized_history.history)\n",
    "        scores = optimized_model.evaluate(self.x_test, self.y_test)\n",
    "        print(\"{}: {}\".format(optimized_model.metrics_names[0], scores[0]))\n",
    "        print(\"{}: {}%\".format(optimized_model.metrics_names[1], scores[1]*100))\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5)                 25        \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 3)                 18        \n",
      "=================================================================\n",
      "Total params: 93\n",
      "Trainable params: 93\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.4944 - acc: 0.3083\n",
      "Epoch 2/30\n",
      "120/120 [==============================] - 0s 92us/step - loss: 0.4927 - acc: 0.3083\n",
      "Epoch 3/30\n",
      "120/120 [==============================] - 0s 86us/step - loss: 0.4910 - acc: 0.3083\n",
      "Epoch 4/30\n",
      "120/120 [==============================] - 0s 127us/step - loss: 0.4893 - acc: 0.3083\n",
      "Epoch 5/30\n",
      "120/120 [==============================] - 0s 111us/step - loss: 0.4876 - acc: 0.3083\n",
      "Epoch 6/30\n",
      "120/120 [==============================] - 0s 116us/step - loss: 0.4859 - acc: 0.3250\n",
      "Epoch 7/30\n",
      "120/120 [==============================] - 0s 112us/step - loss: 0.4842 - acc: 0.3833\n",
      "Epoch 8/30\n",
      "120/120 [==============================] - 0s 91us/step - loss: 0.4824 - acc: 0.3333\n",
      "Epoch 9/30\n",
      "120/120 [==============================] - 0s 108us/step - loss: 0.4807 - acc: 0.3333\n",
      "Epoch 10/30\n",
      "120/120 [==============================] - 0s 107us/step - loss: 0.4791 - acc: 0.3333\n",
      "Epoch 11/30\n",
      "120/120 [==============================] - 0s 93us/step - loss: 0.4774 - acc: 0.3333\n",
      "Epoch 12/30\n",
      "120/120 [==============================] - 0s 107us/step - loss: 0.4756 - acc: 0.3333\n",
      "Epoch 13/30\n",
      "120/120 [==============================] - 0s 104us/step - loss: 0.4740 - acc: 0.3333\n",
      "Epoch 14/30\n",
      "120/120 [==============================] - 0s 105us/step - loss: 0.4723 - acc: 0.3333\n",
      "Epoch 15/30\n",
      "120/120 [==============================] - 0s 112us/step - loss: 0.4706 - acc: 0.3333\n",
      "Epoch 16/30\n",
      "120/120 [==============================] - 0s 103us/step - loss: 0.4690 - acc: 0.3333\n",
      "Epoch 17/30\n",
      "120/120 [==============================] - 0s 115us/step - loss: 0.4673 - acc: 0.3333\n",
      "Epoch 18/30\n",
      "120/120 [==============================] - 0s 115us/step - loss: 0.4657 - acc: 0.3333\n",
      "Epoch 19/30\n",
      "120/120 [==============================] - 0s 109us/step - loss: 0.4640 - acc: 0.3333\n",
      "Epoch 20/30\n",
      "120/120 [==============================] - 0s 113us/step - loss: 0.4624 - acc: 0.3333\n",
      "Epoch 21/30\n",
      "120/120 [==============================] - 0s 127us/step - loss: 0.4607 - acc: 0.3333\n",
      "Epoch 22/30\n",
      "120/120 [==============================] - 0s 110us/step - loss: 0.4591 - acc: 0.3333\n",
      "Epoch 23/30\n",
      "120/120 [==============================] - 0s 113us/step - loss: 0.4575 - acc: 0.3333\n",
      "Epoch 24/30\n",
      "120/120 [==============================] - 0s 105us/step - loss: 0.4560 - acc: 0.3333\n",
      "Epoch 25/30\n",
      "120/120 [==============================] - 0s 116us/step - loss: 0.4544 - acc: 0.3333\n",
      "Epoch 26/30\n",
      "120/120 [==============================] - 0s 123us/step - loss: 0.4528 - acc: 0.3333\n",
      "Epoch 27/30\n",
      "120/120 [==============================] - 0s 118us/step - loss: 0.4512 - acc: 0.3333\n",
      "Epoch 28/30\n",
      "120/120 [==============================] - 0s 121us/step - loss: 0.4497 - acc: 0.3333\n",
      "Epoch 29/30\n",
      "120/120 [==============================] - 0s 112us/step - loss: 0.4481 - acc: 0.3333\n",
      "Epoch 30/30\n",
      "120/120 [==============================] - 0s 139us/step - loss: 0.4466 - acc: 0.3333\n",
      "30/30 [==============================] - 0s 1ms/step\n",
      "loss: 0.43841227889060974\n",
      "acc: 33.33333432674408%\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_5 (Dense)              (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 5)                 25        \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 3)                 18        \n",
      "=================================================================\n",
      "Total params: 123\n",
      "Trainable params: 123\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.5005 - acc: 0.3583\n",
      "Epoch 2/30\n",
      "120/120 [==============================] - 0s 101us/step - loss: 0.4990 - acc: 0.3583\n",
      "Epoch 3/30\n",
      "120/120 [==============================] - 0s 115us/step - loss: 0.4975 - acc: 0.3583\n",
      "Epoch 4/30\n",
      "120/120 [==============================] - 0s 133us/step - loss: 0.4960 - acc: 0.3583\n",
      "Epoch 5/30\n",
      "120/120 [==============================] - 0s 100us/step - loss: 0.4945 - acc: 0.3583\n",
      "Epoch 6/30\n",
      "120/120 [==============================] - 0s 154us/step - loss: 0.4931 - acc: 0.3583\n",
      "Epoch 7/30\n",
      "120/120 [==============================] - 0s 135us/step - loss: 0.4916 - acc: 0.3583\n",
      "Epoch 8/30\n",
      "120/120 [==============================] - 0s 131us/step - loss: 0.4901 - acc: 0.3583\n",
      "Epoch 9/30\n",
      "120/120 [==============================] - 0s 129us/step - loss: 0.4887 - acc: 0.3583\n",
      "Epoch 10/30\n",
      "120/120 [==============================] - 0s 124us/step - loss: 0.4872 - acc: 0.3583\n",
      "Epoch 11/30\n",
      "120/120 [==============================] - 0s 145us/step - loss: 0.4858 - acc: 0.3583\n",
      "Epoch 12/30\n",
      "120/120 [==============================] - 0s 138us/step - loss: 0.4844 - acc: 0.3583\n",
      "Epoch 13/30\n",
      "120/120 [==============================] - 0s 132us/step - loss: 0.4829 - acc: 0.3583\n",
      "Epoch 14/30\n",
      "120/120 [==============================] - 0s 140us/step - loss: 0.4815 - acc: 0.3583\n",
      "Epoch 15/30\n",
      "120/120 [==============================] - 0s 131us/step - loss: 0.4801 - acc: 0.3583\n",
      "Epoch 16/30\n",
      "120/120 [==============================] - 0s 129us/step - loss: 0.4786 - acc: 0.3583\n",
      "Epoch 17/30\n",
      "120/120 [==============================] - 0s 129us/step - loss: 0.4772 - acc: 0.3583\n",
      "Epoch 18/30\n",
      "120/120 [==============================] - 0s 127us/step - loss: 0.4757 - acc: 0.3583\n",
      "Epoch 19/30\n",
      "120/120 [==============================] - 0s 125us/step - loss: 0.4743 - acc: 0.3583\n",
      "Epoch 20/30\n",
      "120/120 [==============================] - 0s 148us/step - loss: 0.4729 - acc: 0.3583\n",
      "Epoch 21/30\n",
      "120/120 [==============================] - 0s 133us/step - loss: 0.4715 - acc: 0.3583\n",
      "Epoch 22/30\n",
      "120/120 [==============================] - 0s 130us/step - loss: 0.4700 - acc: 0.3583\n",
      "Epoch 23/30\n",
      "120/120 [==============================] - 0s 134us/step - loss: 0.4686 - acc: 0.3583\n",
      "Epoch 24/30\n",
      "120/120 [==============================] - 0s 135us/step - loss: 0.4672 - acc: 0.3583\n",
      "Epoch 25/30\n",
      "120/120 [==============================] - 0s 114us/step - loss: 0.4658 - acc: 0.3583\n",
      "Epoch 26/30\n",
      "120/120 [==============================] - 0s 141us/step - loss: 0.4644 - acc: 0.3583\n",
      "Epoch 27/30\n",
      "120/120 [==============================] - 0s 126us/step - loss: 0.4630 - acc: 0.3583\n",
      "Epoch 28/30\n",
      "120/120 [==============================] - 0s 132us/step - loss: 0.4616 - acc: 0.3583\n",
      "Epoch 29/30\n",
      "120/120 [==============================] - 0s 105us/step - loss: 0.4602 - acc: 0.3583\n",
      "Epoch 30/30\n",
      "120/120 [==============================] - 0s 136us/step - loss: 0.4588 - acc: 0.3583\n",
      "30/30 [==============================] - 0s 2ms/step\n",
      "loss: 0.459951788187027\n",
      "acc: 23.333333432674408%\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_10 (Dense)             (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 5)                 25        \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 3)                 18        \n",
      "=================================================================\n",
      "Total params: 153\n",
      "Trainable params: 153\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "120/120 [==============================] - 1s 6ms/step - loss: 0.5246 - acc: 0.3083\n",
      "Epoch 2/30\n",
      "120/120 [==============================] - 0s 121us/step - loss: 0.5231 - acc: 0.3083\n",
      "Epoch 3/30\n",
      "120/120 [==============================] - 0s 129us/step - loss: 0.5216 - acc: 0.3083\n",
      "Epoch 4/30\n",
      "120/120 [==============================] - 0s 109us/step - loss: 0.5201 - acc: 0.3083\n",
      "Epoch 5/30\n",
      "120/120 [==============================] - 0s 166us/step - loss: 0.5186 - acc: 0.3083\n",
      "Epoch 6/30\n",
      "120/120 [==============================] - 0s 117us/step - loss: 0.5172 - acc: 0.3083\n",
      "Epoch 7/30\n",
      "120/120 [==============================] - 0s 129us/step - loss: 0.5156 - acc: 0.3083\n",
      "Epoch 8/30\n",
      "120/120 [==============================] - 0s 112us/step - loss: 0.5142 - acc: 0.3083\n",
      "Epoch 9/30\n",
      "120/120 [==============================] - 0s 118us/step - loss: 0.5127 - acc: 0.3083\n",
      "Epoch 10/30\n",
      "120/120 [==============================] - 0s 131us/step - loss: 0.5112 - acc: 0.3083\n",
      "Epoch 11/30\n",
      "120/120 [==============================] - 0s 127us/step - loss: 0.5097 - acc: 0.3083\n",
      "Epoch 12/30\n",
      "120/120 [==============================] - 0s 117us/step - loss: 0.5081 - acc: 0.3083\n",
      "Epoch 13/30\n",
      "120/120 [==============================] - 0s 121us/step - loss: 0.5066 - acc: 0.3083\n",
      "Epoch 14/30\n",
      "120/120 [==============================] - 0s 125us/step - loss: 0.5051 - acc: 0.3083\n",
      "Epoch 15/30\n",
      "120/120 [==============================] - 0s 130us/step - loss: 0.5035 - acc: 0.3083\n",
      "Epoch 16/30\n",
      "120/120 [==============================] - 0s 128us/step - loss: 0.5021 - acc: 0.3083\n",
      "Epoch 17/30\n",
      "120/120 [==============================] - 0s 124us/step - loss: 0.5005 - acc: 0.3083\n",
      "Epoch 18/30\n",
      "120/120 [==============================] - 0s 121us/step - loss: 0.4990 - acc: 0.3083\n",
      "Epoch 19/30\n",
      "120/120 [==============================] - 0s 127us/step - loss: 0.4975 - acc: 0.3083\n",
      "Epoch 20/30\n",
      "120/120 [==============================] - 0s 120us/step - loss: 0.4960 - acc: 0.3083\n",
      "Epoch 21/30\n",
      "120/120 [==============================] - 0s 120us/step - loss: 0.4944 - acc: 0.3083\n",
      "Epoch 22/30\n",
      "120/120 [==============================] - 0s 124us/step - loss: 0.4929 - acc: 0.3083\n",
      "Epoch 23/30\n",
      "120/120 [==============================] - 0s 143us/step - loss: 0.4914 - acc: 0.3083\n",
      "Epoch 24/30\n",
      "120/120 [==============================] - 0s 136us/step - loss: 0.4899 - acc: 0.3083\n",
      "Epoch 25/30\n",
      "120/120 [==============================] - 0s 122us/step - loss: 0.4884 - acc: 0.3083\n",
      "Epoch 26/30\n",
      "120/120 [==============================] - 0s 127us/step - loss: 0.4868 - acc: 0.3083\n",
      "Epoch 27/30\n",
      "120/120 [==============================] - 0s 125us/step - loss: 0.4853 - acc: 0.3083\n",
      "Epoch 28/30\n",
      "120/120 [==============================] - 0s 123us/step - loss: 0.4838 - acc: 0.3083\n",
      "Epoch 29/30\n",
      "120/120 [==============================] - 0s 141us/step - loss: 0.4823 - acc: 0.3083\n",
      "Epoch 30/30\n",
      "120/120 [==============================] - 0s 153us/step - loss: 0.4808 - acc: 0.3083\n",
      "30/30 [==============================] - 0s 3ms/step\n",
      "loss: 0.4491589665412903\n",
      "acc: 43.33333373069763%\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_16 (Dense)             (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 5)                 25        \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 3)                 18        \n",
      "=================================================================\n",
      "Total params: 183\n",
      "Trainable params: 183\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "120/120 [==============================] - 1s 7ms/step - loss: 0.4377 - acc: 0.3333\n",
      "Epoch 2/30\n",
      "120/120 [==============================] - 0s 130us/step - loss: 0.4361 - acc: 0.3333\n",
      "Epoch 3/30\n",
      "120/120 [==============================] - 0s 138us/step - loss: 0.4346 - acc: 0.3333\n",
      "Epoch 4/30\n",
      "120/120 [==============================] - 0s 133us/step - loss: 0.4330 - acc: 0.3333\n",
      "Epoch 5/30\n",
      "120/120 [==============================] - 0s 140us/step - loss: 0.4314 - acc: 0.3333\n",
      "Epoch 6/30\n",
      "120/120 [==============================] - 0s 142us/step - loss: 0.4299 - acc: 0.3333\n",
      "Epoch 7/30\n",
      "120/120 [==============================] - 0s 133us/step - loss: 0.4283 - acc: 0.3333\n",
      "Epoch 8/30\n",
      "120/120 [==============================] - 0s 147us/step - loss: 0.4268 - acc: 0.3333\n",
      "Epoch 9/30\n",
      "120/120 [==============================] - 0s 123us/step - loss: 0.4253 - acc: 0.3333\n",
      "Epoch 10/30\n",
      "120/120 [==============================] - 0s 147us/step - loss: 0.4237 - acc: 0.3333\n",
      "Epoch 11/30\n",
      "120/120 [==============================] - 0s 140us/step - loss: 0.4222 - acc: 0.3333\n",
      "Epoch 12/30\n",
      "120/120 [==============================] - 0s 132us/step - loss: 0.4207 - acc: 0.3333\n",
      "Epoch 13/30\n",
      "120/120 [==============================] - 0s 126us/step - loss: 0.4192 - acc: 0.3333\n",
      "Epoch 14/30\n",
      "120/120 [==============================] - 0s 140us/step - loss: 0.4178 - acc: 0.3333\n",
      "Epoch 15/30\n",
      "120/120 [==============================] - 0s 137us/step - loss: 0.4163 - acc: 0.3333\n",
      "Epoch 16/30\n",
      "120/120 [==============================] - 0s 148us/step - loss: 0.4149 - acc: 0.3333\n",
      "Epoch 17/30\n",
      "120/120 [==============================] - 0s 125us/step - loss: 0.4134 - acc: 0.3333\n",
      "Epoch 18/30\n",
      "120/120 [==============================] - 0s 118us/step - loss: 0.4120 - acc: 0.3333\n",
      "Epoch 19/30\n",
      "120/120 [==============================] - 0s 164us/step - loss: 0.4106 - acc: 0.3333\n",
      "Epoch 20/30\n",
      "120/120 [==============================] - 0s 137us/step - loss: 0.4093 - acc: 0.3333\n",
      "Epoch 21/30\n",
      "120/120 [==============================] - 0s 134us/step - loss: 0.4079 - acc: 0.3333\n",
      "Epoch 22/30\n",
      "120/120 [==============================] - 0s 138us/step - loss: 0.4066 - acc: 0.3333\n",
      "Epoch 23/30\n",
      "120/120 [==============================] - 0s 134us/step - loss: 0.4052 - acc: 0.3333\n",
      "Epoch 24/30\n",
      "120/120 [==============================] - 0s 147us/step - loss: 0.4039 - acc: 0.3333\n",
      "Epoch 25/30\n",
      "120/120 [==============================] - 0s 131us/step - loss: 0.4026 - acc: 0.3333\n",
      "Epoch 26/30\n",
      "120/120 [==============================] - 0s 124us/step - loss: 0.4014 - acc: 0.3333\n",
      "Epoch 27/30\n",
      "120/120 [==============================] - 0s 134us/step - loss: 0.4001 - acc: 0.3333\n",
      "Epoch 28/30\n",
      "120/120 [==============================] - 0s 133us/step - loss: 0.3989 - acc: 0.3333\n",
      "Epoch 29/30\n",
      "120/120 [==============================] - 0s 120us/step - loss: 0.3977 - acc: 0.3333\n",
      "Epoch 30/30\n",
      "120/120 [==============================] - 0s 159us/step - loss: 0.3965 - acc: 0.3333\n",
      "30/30 [==============================] - 0s 5ms/step\n",
      "loss: 0.3912700414657593\n",
      "acc: 33.33333432674408%\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_23 (Dense)             (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 5)                 25        \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 3)                 18        \n",
      "=================================================================\n",
      "Total params: 213\n",
      "Trainable params: 213\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "120/120 [==============================] - 1s 9ms/step - loss: 0.5225 - acc: 0.3583\n",
      "Epoch 2/30\n",
      "120/120 [==============================] - 0s 146us/step - loss: 0.5215 - acc: 0.3583\n",
      "Epoch 3/30\n",
      "120/120 [==============================] - 0s 150us/step - loss: 0.5205 - acc: 0.3583\n",
      "Epoch 4/30\n",
      "120/120 [==============================] - 0s 137us/step - loss: 0.5195 - acc: 0.3583\n",
      "Epoch 5/30\n",
      "120/120 [==============================] - 0s 157us/step - loss: 0.5185 - acc: 0.3583\n",
      "Epoch 6/30\n",
      "120/120 [==============================] - 0s 133us/step - loss: 0.5174 - acc: 0.3583\n",
      "Epoch 7/30\n",
      "120/120 [==============================] - 0s 150us/step - loss: 0.5164 - acc: 0.3583\n",
      "Epoch 8/30\n",
      "120/120 [==============================] - 0s 140us/step - loss: 0.5154 - acc: 0.3583\n",
      "Epoch 9/30\n",
      "120/120 [==============================] - 0s 154us/step - loss: 0.5144 - acc: 0.3583\n",
      "Epoch 10/30\n",
      "120/120 [==============================] - 0s 133us/step - loss: 0.5133 - acc: 0.3583\n",
      "Epoch 11/30\n",
      "120/120 [==============================] - 0s 138us/step - loss: 0.5124 - acc: 0.3583\n",
      "Epoch 12/30\n",
      "120/120 [==============================] - 0s 140us/step - loss: 0.5113 - acc: 0.3583\n",
      "Epoch 13/30\n",
      "120/120 [==============================] - 0s 167us/step - loss: 0.5103 - acc: 0.3583\n",
      "Epoch 14/30\n",
      "120/120 [==============================] - 0s 144us/step - loss: 0.5093 - acc: 0.3583\n",
      "Epoch 15/30\n",
      "120/120 [==============================] - 0s 142us/step - loss: 0.5083 - acc: 0.3583\n",
      "Epoch 16/30\n",
      "120/120 [==============================] - 0s 152us/step - loss: 0.5073 - acc: 0.3583\n",
      "Epoch 17/30\n",
      "120/120 [==============================] - 0s 168us/step - loss: 0.5063 - acc: 0.3583\n",
      "Epoch 18/30\n",
      "120/120 [==============================] - 0s 161us/step - loss: 0.5053 - acc: 0.3583\n",
      "Epoch 19/30\n",
      "120/120 [==============================] - 0s 146us/step - loss: 0.5043 - acc: 0.3583\n",
      "Epoch 20/30\n",
      "120/120 [==============================] - 0s 140us/step - loss: 0.5033 - acc: 0.3583\n",
      "Epoch 21/30\n",
      "120/120 [==============================] - 0s 137us/step - loss: 0.5023 - acc: 0.3583\n",
      "Epoch 22/30\n",
      "120/120 [==============================] - 0s 182us/step - loss: 0.5012 - acc: 0.3583\n",
      "Epoch 23/30\n",
      "120/120 [==============================] - 0s 151us/step - loss: 0.5002 - acc: 0.3583\n",
      "Epoch 24/30\n",
      "120/120 [==============================] - 0s 151us/step - loss: 0.4993 - acc: 0.3583\n",
      "Epoch 25/30\n",
      "120/120 [==============================] - 0s 134us/step - loss: 0.4982 - acc: 0.3583\n",
      "Epoch 26/30\n",
      "120/120 [==============================] - 0s 145us/step - loss: 0.4972 - acc: 0.3583\n",
      "Epoch 27/30\n",
      "120/120 [==============================] - 0s 140us/step - loss: 0.4962 - acc: 0.3583\n",
      "Epoch 28/30\n",
      "120/120 [==============================] - 0s 149us/step - loss: 0.4952 - acc: 0.3583\n",
      "Epoch 29/30\n",
      "120/120 [==============================] - 0s 146us/step - loss: 0.4941 - acc: 0.3583\n",
      "Epoch 30/30\n",
      "120/120 [==============================] - 0s 145us/step - loss: 0.4931 - acc: 0.3583\n",
      "30/30 [==============================] - 0s 6ms/step\n",
      "loss: 0.5100219249725342\n",
      "acc: 23.333333432674408%\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_31 (Dense)             (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 5)                 25        \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 3)                 18        \n",
      "=================================================================\n",
      "Total params: 243\n",
      "Trainable params: 243\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "120/120 [==============================] - 1s 10ms/step - loss: 0.5263 - acc: 0.3583\n",
      "Epoch 2/30\n",
      "120/120 [==============================] - 0s 154us/step - loss: 0.5246 - acc: 0.3583\n",
      "Epoch 3/30\n",
      "120/120 [==============================] - 0s 161us/step - loss: 0.5230 - acc: 0.3583\n",
      "Epoch 4/30\n",
      "120/120 [==============================] - 0s 172us/step - loss: 0.5213 - acc: 0.3583\n",
      "Epoch 5/30\n",
      "120/120 [==============================] - 0s 145us/step - loss: 0.5196 - acc: 0.3583\n",
      "Epoch 6/30\n",
      "120/120 [==============================] - 0s 153us/step - loss: 0.5179 - acc: 0.3583\n",
      "Epoch 7/30\n",
      "120/120 [==============================] - 0s 192us/step - loss: 0.5163 - acc: 0.3583\n",
      "Epoch 8/30\n",
      "120/120 [==============================] - 0s 158us/step - loss: 0.5146 - acc: 0.3583\n",
      "Epoch 9/30\n",
      "120/120 [==============================] - 0s 152us/step - loss: 0.5130 - acc: 0.3583\n",
      "Epoch 10/30\n",
      "120/120 [==============================] - 0s 162us/step - loss: 0.5114 - acc: 0.3583\n",
      "Epoch 11/30\n",
      "120/120 [==============================] - 0s 172us/step - loss: 0.5097 - acc: 0.3583\n",
      "Epoch 12/30\n",
      "120/120 [==============================] - 0s 182us/step - loss: 0.5081 - acc: 0.3583\n",
      "Epoch 13/30\n",
      "120/120 [==============================] - 0s 159us/step - loss: 0.5065 - acc: 0.3583\n",
      "Epoch 14/30\n",
      "120/120 [==============================] - 0s 152us/step - loss: 0.5049 - acc: 0.3583\n",
      "Epoch 15/30\n",
      "120/120 [==============================] - 0s 153us/step - loss: 0.5033 - acc: 0.3583\n",
      "Epoch 16/30\n",
      "120/120 [==============================] - 0s 158us/step - loss: 0.5016 - acc: 0.3583\n",
      "Epoch 17/30\n",
      "120/120 [==============================] - 0s 146us/step - loss: 0.5000 - acc: 0.3583\n",
      "Epoch 18/30\n",
      "120/120 [==============================] - 0s 196us/step - loss: 0.4984 - acc: 0.3583\n",
      "Epoch 19/30\n",
      "120/120 [==============================] - 0s 152us/step - loss: 0.4968 - acc: 0.3583\n",
      "Epoch 20/30\n",
      "120/120 [==============================] - 0s 175us/step - loss: 0.4952 - acc: 0.3583\n",
      "Epoch 21/30\n",
      "120/120 [==============================] - 0s 149us/step - loss: 0.4936 - acc: 0.3583\n",
      "Epoch 22/30\n",
      "120/120 [==============================] - 0s 156us/step - loss: 0.4920 - acc: 0.3583\n",
      "Epoch 23/30\n",
      "120/120 [==============================] - 0s 165us/step - loss: 0.4905 - acc: 0.3583\n",
      "Epoch 24/30\n",
      "120/120 [==============================] - 0s 150us/step - loss: 0.4889 - acc: 0.3583\n",
      "Epoch 25/30\n",
      "120/120 [==============================] - 0s 154us/step - loss: 0.4873 - acc: 0.3583\n",
      "Epoch 26/30\n",
      "120/120 [==============================] - 0s 182us/step - loss: 0.4857 - acc: 0.3583\n",
      "Epoch 27/30\n",
      "120/120 [==============================] - 0s 185us/step - loss: 0.4842 - acc: 0.3583\n",
      "Epoch 28/30\n",
      "120/120 [==============================] - 0s 200us/step - loss: 0.4826 - acc: 0.3583\n",
      "Epoch 29/30\n",
      "120/120 [==============================] - 0s 187us/step - loss: 0.4811 - acc: 0.3583\n",
      "Epoch 30/30\n",
      "120/120 [==============================] - 0s 191us/step - loss: 0.4795 - acc: 0.3583\n",
      "30/30 [==============================] - 0s 8ms/step\n",
      "loss: 0.4874107539653778\n",
      "acc: 23.333333432674408%\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_40 (Dense)             (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 5)                 25        \n",
      "_________________________________________________________________\n",
      "dense_42 (Dense)             (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "dense_43 (Dense)             (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "dense_44 (Dense)             (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "dense_45 (Dense)             (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "dense_46 (Dense)             (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "dense_47 (Dense)             (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "dense_48 (Dense)             (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "dense_49 (Dense)             (None, 3)                 18        \n",
      "=================================================================\n",
      "Total params: 273\n",
      "Trainable params: 273\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "120/120 [==============================] - 1s 11ms/step - loss: 0.4903 - acc: 0.3333\n",
      "Epoch 2/30\n",
      "120/120 [==============================] - 0s 211us/step - loss: 0.4889 - acc: 0.3333\n",
      "Epoch 3/30\n",
      "120/120 [==============================] - 0s 205us/step - loss: 0.4876 - acc: 0.3333\n",
      "Epoch 4/30\n",
      "120/120 [==============================] - 0s 195us/step - loss: 0.4863 - acc: 0.3333\n",
      "Epoch 5/30\n",
      "120/120 [==============================] - 0s 223us/step - loss: 0.4849 - acc: 0.3333\n",
      "Epoch 6/30\n",
      "120/120 [==============================] - 0s 166us/step - loss: 0.4836 - acc: 0.3333\n",
      "Epoch 7/30\n",
      "120/120 [==============================] - 0s 163us/step - loss: 0.4822 - acc: 0.3333\n",
      "Epoch 8/30\n",
      "120/120 [==============================] - 0s 161us/step - loss: 0.4808 - acc: 0.3333\n",
      "Epoch 9/30\n",
      "120/120 [==============================] - 0s 163us/step - loss: 0.4795 - acc: 0.3333\n",
      "Epoch 10/30\n",
      "120/120 [==============================] - 0s 163us/step - loss: 0.4781 - acc: 0.3333\n",
      "Epoch 11/30\n",
      "120/120 [==============================] - 0s 177us/step - loss: 0.4768 - acc: 0.3333\n",
      "Epoch 12/30\n",
      "120/120 [==============================] - 0s 164us/step - loss: 0.4754 - acc: 0.3333\n",
      "Epoch 13/30\n",
      "120/120 [==============================] - 0s 162us/step - loss: 0.4741 - acc: 0.3333\n",
      "Epoch 14/30\n",
      "120/120 [==============================] - 0s 179us/step - loss: 0.4728 - acc: 0.3333\n",
      "Epoch 15/30\n",
      "120/120 [==============================] - 0s 167us/step - loss: 0.4714 - acc: 0.3333\n",
      "Epoch 16/30\n",
      "120/120 [==============================] - 0s 170us/step - loss: 0.4700 - acc: 0.3333\n",
      "Epoch 17/30\n",
      "120/120 [==============================] - 0s 167us/step - loss: 0.4687 - acc: 0.3333\n",
      "Epoch 18/30\n",
      "120/120 [==============================] - 0s 158us/step - loss: 0.4674 - acc: 0.3333\n",
      "Epoch 19/30\n",
      "120/120 [==============================] - 0s 170us/step - loss: 0.4660 - acc: 0.3333\n",
      "Epoch 20/30\n",
      "120/120 [==============================] - 0s 170us/step - loss: 0.4647 - acc: 0.3333\n",
      "Epoch 21/30\n",
      "120/120 [==============================] - 0s 181us/step - loss: 0.4634 - acc: 0.3333\n",
      "Epoch 22/30\n",
      "120/120 [==============================] - 0s 174us/step - loss: 0.4620 - acc: 0.3333\n",
      "Epoch 23/30\n",
      "120/120 [==============================] - 0s 163us/step - loss: 0.4607 - acc: 0.3333\n",
      "Epoch 24/30\n",
      "120/120 [==============================] - 0s 165us/step - loss: 0.4593 - acc: 0.3333\n",
      "Epoch 25/30\n",
      "120/120 [==============================] - 0s 163us/step - loss: 0.4580 - acc: 0.3333\n",
      "Epoch 26/30\n",
      "120/120 [==============================] - 0s 158us/step - loss: 0.4567 - acc: 0.3333\n",
      "Epoch 27/30\n",
      "120/120 [==============================] - 0s 184us/step - loss: 0.4554 - acc: 0.3333\n",
      "Epoch 28/30\n",
      "120/120 [==============================] - 0s 182us/step - loss: 0.4540 - acc: 0.3333\n",
      "Epoch 29/30\n",
      "120/120 [==============================] - 0s 193us/step - loss: 0.4527 - acc: 0.3333\n",
      "Epoch 30/30\n",
      "120/120 [==============================] - 0s 167us/step - loss: 0.4514 - acc: 0.3333\n",
      "30/30 [==============================] - 0s 9ms/step\n",
      "loss: 0.45852312445640564\n",
      "acc: 33.33333432674408%\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_50 (Dense)             (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "dense_51 (Dense)             (None, 5)                 25        \n",
      "_________________________________________________________________\n",
      "dense_52 (Dense)             (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "dense_53 (Dense)             (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "dense_54 (Dense)             (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "dense_55 (Dense)             (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "dense_56 (Dense)             (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "dense_57 (Dense)             (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "dense_58 (Dense)             (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "dense_59 (Dense)             (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "dense_60 (Dense)             (None, 3)                 18        \n",
      "=================================================================\n",
      "Total params: 303\n",
      "Trainable params: 303\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "120/120 [==============================] - 2s 13ms/step - loss: 0.5290 - acc: 0.3333\n",
      "Epoch 2/30\n",
      "120/120 [==============================] - 0s 199us/step - loss: 0.5274 - acc: 0.3333\n",
      "Epoch 3/30\n",
      "120/120 [==============================] - 0s 204us/step - loss: 0.5258 - acc: 0.3333\n",
      "Epoch 4/30\n",
      "120/120 [==============================] - 0s 219us/step - loss: 0.5242 - acc: 0.3333\n",
      "Epoch 5/30\n",
      "120/120 [==============================] - 0s 218us/step - loss: 0.5227 - acc: 0.3333\n",
      "Epoch 6/30\n",
      "120/120 [==============================] - 0s 215us/step - loss: 0.5212 - acc: 0.3333\n",
      "Epoch 7/30\n",
      "120/120 [==============================] - 0s 214us/step - loss: 0.5197 - acc: 0.3333\n",
      "Epoch 8/30\n",
      "120/120 [==============================] - 0s 218us/step - loss: 0.5181 - acc: 0.3333\n",
      "Epoch 9/30\n",
      "120/120 [==============================] - 0s 212us/step - loss: 0.5166 - acc: 0.3333\n",
      "Epoch 10/30\n",
      "120/120 [==============================] - 0s 224us/step - loss: 0.5151 - acc: 0.3333\n",
      "Epoch 11/30\n",
      "120/120 [==============================] - 0s 218us/step - loss: 0.5135 - acc: 0.3333\n",
      "Epoch 12/30\n",
      "120/120 [==============================] - 0s 222us/step - loss: 0.5120 - acc: 0.3333\n",
      "Epoch 13/30\n",
      "120/120 [==============================] - 0s 229us/step - loss: 0.5104 - acc: 0.3333\n",
      "Epoch 14/30\n",
      "120/120 [==============================] - 0s 217us/step - loss: 0.5089 - acc: 0.3333\n",
      "Epoch 15/30\n",
      "120/120 [==============================] - 0s 206us/step - loss: 0.5074 - acc: 0.3167\n",
      "Epoch 16/30\n",
      "120/120 [==============================] - 0s 175us/step - loss: 0.5059 - acc: 0.3583\n",
      "Epoch 17/30\n",
      "120/120 [==============================] - 0s 171us/step - loss: 0.5043 - acc: 0.3583\n",
      "Epoch 18/30\n",
      "120/120 [==============================] - 0s 187us/step - loss: 0.5028 - acc: 0.3583\n",
      "Epoch 19/30\n",
      "120/120 [==============================] - 0s 177us/step - loss: 0.5013 - acc: 0.3583\n",
      "Epoch 20/30\n",
      "120/120 [==============================] - 0s 198us/step - loss: 0.4998 - acc: 0.3583\n",
      "Epoch 21/30\n",
      "120/120 [==============================] - 0s 190us/step - loss: 0.4983 - acc: 0.3583\n",
      "Epoch 22/30\n",
      "120/120 [==============================] - 0s 186us/step - loss: 0.4968 - acc: 0.3583\n",
      "Epoch 23/30\n",
      "120/120 [==============================] - 0s 172us/step - loss: 0.4953 - acc: 0.3583\n",
      "Epoch 24/30\n",
      "120/120 [==============================] - 0s 176us/step - loss: 0.4938 - acc: 0.3583\n",
      "Epoch 25/30\n",
      "120/120 [==============================] - 0s 182us/step - loss: 0.4923 - acc: 0.3583\n",
      "Epoch 26/30\n",
      "120/120 [==============================] - 0s 179us/step - loss: 0.4908 - acc: 0.3583\n",
      "Epoch 27/30\n",
      "120/120 [==============================] - 0s 196us/step - loss: 0.4894 - acc: 0.3583\n",
      "Epoch 28/30\n",
      "120/120 [==============================] - 0s 177us/step - loss: 0.4879 - acc: 0.3583\n",
      "Epoch 29/30\n",
      "120/120 [==============================] - 0s 179us/step - loss: 0.4864 - acc: 0.3583\n",
      "Epoch 30/30\n",
      "120/120 [==============================] - 0s 178us/step - loss: 0.4850 - acc: 0.3583\n",
      "30/30 [==============================] - 0s 11ms/step\n",
      "loss: 0.5083547830581665\n",
      "acc: 23.333333432674408%\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_61 (Dense)             (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "dense_62 (Dense)             (None, 5)                 25        \n",
      "_________________________________________________________________\n",
      "dense_63 (Dense)             (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "dense_64 (Dense)             (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "dense_65 (Dense)             (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "dense_66 (Dense)             (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "dense_67 (Dense)             (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "dense_68 (Dense)             (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "dense_69 (Dense)             (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "dense_70 (Dense)             (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "dense_71 (Dense)             (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "dense_72 (Dense)             (None, 3)                 18        \n",
      "=================================================================\n",
      "Total params: 333\n",
      "Trainable params: 333\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "120/120 [==============================] - 2s 13ms/step - loss: 0.5157 - acc: 0.3333\n",
      "Epoch 2/30\n",
      "120/120 [==============================] - 0s 177us/step - loss: 0.5142 - acc: 0.3333\n",
      "Epoch 3/30\n",
      "120/120 [==============================] - 0s 191us/step - loss: 0.5128 - acc: 0.3333\n",
      "Epoch 4/30\n",
      "120/120 [==============================] - 0s 198us/step - loss: 0.5113 - acc: 0.3333\n",
      "Epoch 5/30\n",
      "120/120 [==============================] - 0s 208us/step - loss: 0.5098 - acc: 0.3333\n",
      "Epoch 6/30\n",
      "120/120 [==============================] - 0s 225us/step - loss: 0.5083 - acc: 0.3333\n",
      "Epoch 7/30\n",
      "120/120 [==============================] - 0s 222us/step - loss: 0.5068 - acc: 0.3333\n",
      "Epoch 8/30\n",
      "120/120 [==============================] - 0s 237us/step - loss: 0.5053 - acc: 0.3333\n",
      "Epoch 9/30\n",
      "120/120 [==============================] - 0s 233us/step - loss: 0.5038 - acc: 0.3333\n",
      "Epoch 10/30\n",
      "120/120 [==============================] - 0s 235us/step - loss: 0.5022 - acc: 0.3333\n",
      "Epoch 11/30\n",
      "120/120 [==============================] - 0s 226us/step - loss: 0.5007 - acc: 0.3333\n",
      "Epoch 12/30\n",
      "120/120 [==============================] - 0s 249us/step - loss: 0.4992 - acc: 0.3333\n",
      "Epoch 13/30\n",
      "120/120 [==============================] - 0s 238us/step - loss: 0.4977 - acc: 0.3333\n",
      "Epoch 14/30\n",
      "120/120 [==============================] - 0s 238us/step - loss: 0.4962 - acc: 0.3333\n",
      "Epoch 15/30\n",
      "120/120 [==============================] - 0s 231us/step - loss: 0.4947 - acc: 0.3333\n",
      "Epoch 16/30\n",
      "120/120 [==============================] - 0s 234us/step - loss: 0.4932 - acc: 0.3333\n",
      "Epoch 17/30\n",
      "120/120 [==============================] - 0s 177us/step - loss: 0.4917 - acc: 0.3333\n",
      "Epoch 18/30\n",
      "120/120 [==============================] - 0s 202us/step - loss: 0.4902 - acc: 0.3333\n",
      "Epoch 19/30\n",
      "120/120 [==============================] - 0s 176us/step - loss: 0.4887 - acc: 0.3333\n",
      "Epoch 20/30\n",
      "120/120 [==============================] - 0s 185us/step - loss: 0.4872 - acc: 0.3333\n",
      "Epoch 21/30\n",
      "120/120 [==============================] - 0s 200us/step - loss: 0.4857 - acc: 0.3333\n",
      "Epoch 22/30\n",
      "120/120 [==============================] - 0s 179us/step - loss: 0.4842 - acc: 0.3333\n",
      "Epoch 23/30\n",
      "120/120 [==============================] - 0s 197us/step - loss: 0.4827 - acc: 0.3333\n",
      "Epoch 24/30\n",
      "120/120 [==============================] - 0s 186us/step - loss: 0.4813 - acc: 0.3333\n",
      "Epoch 25/30\n",
      "120/120 [==============================] - 0s 190us/step - loss: 0.4798 - acc: 0.3333\n",
      "Epoch 26/30\n",
      "120/120 [==============================] - 0s 181us/step - loss: 0.4783 - acc: 0.3333\n",
      "Epoch 27/30\n",
      "120/120 [==============================] - 0s 211us/step - loss: 0.4769 - acc: 0.3333\n",
      "Epoch 28/30\n",
      "120/120 [==============================] - 0s 188us/step - loss: 0.4754 - acc: 0.3333\n",
      "Epoch 29/30\n",
      "120/120 [==============================] - 0s 187us/step - loss: 0.4740 - acc: 0.3333\n",
      "Epoch 30/30\n",
      "120/120 [==============================] - 0s 206us/step - loss: 0.4725 - acc: 0.3333\n",
      "30/30 [==============================] - 0s 13ms/step\n",
      "loss: 0.45692864060401917\n",
      "acc: 33.33333432674408%\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_73 (Dense)             (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "dense_74 (Dense)             (None, 5)                 25        \n",
      "_________________________________________________________________\n",
      "dense_75 (Dense)             (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "dense_76 (Dense)             (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "dense_77 (Dense)             (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "dense_78 (Dense)             (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "dense_79 (Dense)             (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "dense_80 (Dense)             (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "dense_81 (Dense)             (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "dense_82 (Dense)             (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "dense_83 (Dense)             (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "dense_84 (Dense)             (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "dense_85 (Dense)             (None, 3)                 18        \n",
      "=================================================================\n",
      "Total params: 363\n",
      "Trainable params: 363\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "120/120 [==============================] - 2s 14ms/step - loss: 0.4570 - acc: 0.3583\n",
      "Epoch 2/30\n",
      "120/120 [==============================] - 0s 223us/step - loss: 0.4555 - acc: 0.3583\n",
      "Epoch 3/30\n",
      "120/120 [==============================] - 0s 201us/step - loss: 0.4539 - acc: 0.3583\n",
      "Epoch 4/30\n",
      "120/120 [==============================] - 0s 224us/step - loss: 0.4523 - acc: 0.3583\n",
      "Epoch 5/30\n",
      "120/120 [==============================] - 0s 198us/step - loss: 0.4507 - acc: 0.3583\n",
      "Epoch 6/30\n",
      "120/120 [==============================] - 0s 195us/step - loss: 0.4492 - acc: 0.3583\n",
      "Epoch 7/30\n",
      "120/120 [==============================] - 0s 203us/step - loss: 0.4476 - acc: 0.3583\n",
      "Epoch 8/30\n",
      "120/120 [==============================] - 0s 216us/step - loss: 0.4461 - acc: 0.3583\n",
      "Epoch 9/30\n",
      "120/120 [==============================] - 0s 198us/step - loss: 0.4445 - acc: 0.3583\n",
      "Epoch 10/30\n",
      "120/120 [==============================] - 0s 206us/step - loss: 0.4430 - acc: 0.3583\n",
      "Epoch 11/30\n",
      "120/120 [==============================] - 0s 191us/step - loss: 0.4415 - acc: 0.3583\n",
      "Epoch 12/30\n",
      "120/120 [==============================] - 0s 220us/step - loss: 0.4400 - acc: 0.3583\n",
      "Epoch 13/30\n",
      "120/120 [==============================] - 0s 236us/step - loss: 0.4385 - acc: 0.3583\n",
      "Epoch 14/30\n",
      "120/120 [==============================] - 0s 189us/step - loss: 0.4370 - acc: 0.3583\n",
      "Epoch 15/30\n",
      "120/120 [==============================] - 0s 205us/step - loss: 0.4356 - acc: 0.3583\n",
      "Epoch 16/30\n",
      "120/120 [==============================] - 0s 198us/step - loss: 0.4341 - acc: 0.3583\n",
      "Epoch 17/30\n",
      "120/120 [==============================] - 0s 210us/step - loss: 0.4327 - acc: 0.3583\n",
      "Epoch 18/30\n",
      "120/120 [==============================] - 0s 199us/step - loss: 0.4313 - acc: 0.3583\n",
      "Epoch 19/30\n",
      "120/120 [==============================] - 0s 193us/step - loss: 0.4299 - acc: 0.3583\n",
      "Epoch 20/30\n",
      "120/120 [==============================] - 0s 210us/step - loss: 0.4285 - acc: 0.3583\n",
      "Epoch 21/30\n",
      "120/120 [==============================] - 0s 199us/step - loss: 0.4271 - acc: 0.3583\n",
      "Epoch 22/30\n",
      "120/120 [==============================] - 0s 207us/step - loss: 0.4257 - acc: 0.3583\n",
      "Epoch 23/30\n",
      "120/120 [==============================] - 0s 198us/step - loss: 0.4243 - acc: 0.3583\n",
      "Epoch 24/30\n",
      "120/120 [==============================] - 0s 206us/step - loss: 0.4230 - acc: 0.3583\n",
      "Epoch 25/30\n",
      "120/120 [==============================] - 0s 198us/step - loss: 0.4217 - acc: 0.3583\n",
      "Epoch 26/30\n",
      "120/120 [==============================] - 0s 219us/step - loss: 0.4203 - acc: 0.3583\n",
      "Epoch 27/30\n",
      "120/120 [==============================] - 0s 207us/step - loss: 0.4191 - acc: 0.3583\n",
      "Epoch 28/30\n",
      "120/120 [==============================] - 0s 217us/step - loss: 0.4178 - acc: 0.3583\n",
      "Epoch 29/30\n",
      "120/120 [==============================] - 0s 204us/step - loss: 0.4165 - acc: 0.3583\n",
      "Epoch 30/30\n",
      "120/120 [==============================] - 0s 194us/step - loss: 0.4153 - acc: 0.3583\n",
      "30/30 [==============================] - 0s 16ms/step\n",
      "loss: 0.4267161190509796\n",
      "acc: 23.333333432674408%\n",
      "[0.0015939458211263007, 0.0013887270291646308, 0.0014570451445049721, 0.0013729257053799108, 0.0009791792763604072, 0.0015605054299036654, 0.001297723452250164, 0.0014668357372283928, 0.0014403258429633266, 0.0013907553752263379]\n",
      "[<keras.models.Sequential object at 0x1187f1668>, <keras.models.Sequential object at 0x1188e8ba8>, <keras.models.Sequential object at 0x119406e10>, <keras.models.Sequential object at 0x119aa2eb8>, <keras.models.Sequential object at 0x11a4525c0>, <keras.models.Sequential object at 0x11b21bc88>, <keras.models.Sequential object at 0x11bf3afd0>, <keras.models.Sequential object at 0x11cfc4860>, <keras.models.Sequential object at 0x11e48de48>, <keras.models.Sequential object at 0x11dfe8b00>]\n",
      "The optimal model is at index: 1\n",
      "{'loss': [0.5004772663116455, 0.4989621917406718, 0.4974500298500061, 0.4960255781809489, 0.4945165038108826, 0.4930570900440216, 0.4916289468606313, 0.49014347394307456, 0.48868890007336935, 0.4872497538725535, 0.4858030954996745, 0.4843566596508026, 0.4829183320204417, 0.48149161140124, 0.4800756673018138, 0.4786093533039093, 0.4772175133228302, 0.4757395009199778, 0.47432285944620767, 0.47290350596110026, 0.4714557647705078, 0.4700259526570638, 0.46861520608266194, 0.467208594083786, 0.4657910426457723, 0.46439109643300375, 0.46297213435173035, 0.4615734159946442, 0.4601986030737559, 0.45881545543670654], 'acc': [0.3583333353201548, 0.35833333333333334, 0.3583333323399226, 0.3583333373069763, 0.35833333333333334, 0.35833333333333334, 0.35833333333333334, 0.35833333333333334, 0.3583333373069763, 0.3583333353201548, 0.35833333134651185, 0.35833333134651185, 0.3583333353201548, 0.35833333333333334, 0.35833333134651185, 0.35833333333333334, 0.35833333333333334, 0.3583333353201548, 0.35833333134651185, 0.35833333333333334, 0.3583333353201548, 0.3583333353201548, 0.3583333323399226, 0.35833333333333334, 0.35833333333333334, 0.3583333353201548, 0.35833333134651185, 0.35833333333333334, 0.35833333333333334, 0.3583333353201548]}\n",
      "30/30 [==============================] - 0s 45us/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.459951788187027\n",
      "acc: 23.333333432674408%\n"
     ]
    }
   ],
   "source": [
    "NN = KerasNeuralNetwork(x_train, y_train, x_test, y_test)\n",
    "NN.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
