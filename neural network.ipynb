{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Import all packages and libraries for NN\n",
    "\n",
    "import numpy\n",
    "numpy.random.seed()\n",
    "\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.utils import shuffle\n",
    "from keras.utils import np_utils\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "\n",
    "import keras\n",
    "import pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Processing\n",
    "# Preparing Iris dataset for usage as a dataframe\n",
    "# Encoding output variables\n",
    "# Shuffle rows randomly for variety\n",
    "# Spliting dataset to test and train dataframes. Test dataset will be 80% of entire dataframe.\n",
    "# Parsing dataframe to features and labels (x_train and y_train)\n",
    "\n",
    "# Constants\n",
    "_training_split = 0.8\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Load in dataset\n",
    "# Turning training dataframe to x_train and encoded y_train\n",
    "df = pandas.read_csv('iris.csv')\n",
    "df = shuffle(df)\n",
    "features = list(df.columns.values)[:-1]\n",
    "labels = list(df.columns.values)[-1]\n",
    "input_dim = len(list(df.columns.values)[:-1])\n",
    "\n",
    "\n",
    "# Spliting dataframe to training and testing\n",
    "def split_to_training(dataframe):\n",
    "    train_df = dataframe[:int(len(dataframe)*_training_split)]\n",
    "    \n",
    "    return train_df\n",
    "\n",
    "\n",
    "def split_to_testing(dataframe):\n",
    "    test_df = dataframe[int(len(dataframe)*_training_split):]\n",
    "    \n",
    "    return test_df\n",
    "\n",
    "\n",
    "# Spliting training or testing dataset to x and y\n",
    "def split_to_x(dataframe):\n",
    "    x = dataframe[features].values\n",
    "    \n",
    "    return x\n",
    "\n",
    "\n",
    "def split_to_y(dataframe):\n",
    "    y = dataframe[labels].values\n",
    "    \n",
    "    return y\n",
    "\n",
    "\n",
    "# Encoding all labels with HOT Encoder\n",
    "def encode_labels(label_dataframe):\n",
    "    encoder = LabelEncoder()\n",
    "    encoder.fit(label_dataframe)\n",
    "    encoded_y = encoder.transform(label_dataframe)\n",
    "    new_y = np_utils.to_categorical(encoded_y)\n",
    "    \n",
    "    return new_y\n",
    "\n",
    "\n",
    "train_df = split_to_training(df)\n",
    "x_train = split_to_x(train_df)\n",
    "y_train = encode_labels(split_to_y(train_df))\n",
    "\n",
    "test_df = split_to_testing(df)\n",
    "x_test = split_to_x(test_df)\n",
    "y_test = encode_labels(split_to_y(test_df))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KerasNeuralNetwork:\n",
    "    def __init__(self, x_train, y_train, x_test, y_test):\n",
    "        self.x_train = x_train\n",
    "        self.y_train = y_train\n",
    "        self.x_test = x_test\n",
    "        self.y_test = y_test\n",
    "        self.model = Sequential()\n",
    "        \n",
    "        \n",
    "    def run(self):\n",
    "        self.model.add(Dense(8, input_dim=input_dim, activation='relu'))\n",
    "        self.model.add(Dense(5, activation='relu'))\n",
    "        self.model.add(Dense(5, activation='relu'))\n",
    "        self.model.add(Dense(5, activation='relu'))\n",
    "        self.model.add(Dense(3, activation='softmax'))\n",
    "        self.model.summary()\n",
    "        \n",
    "        self.model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "        \n",
    "        history = self.model.fit(self.x_train, self.y_train, epochs=30)\n",
    "        print(history.params)\n",
    "        print(history.history)\n",
    "\n",
    "        \n",
    "    def evaluate(self):\n",
    "        scores = self.model.evaluate(self.x_test, self.y_test)\n",
    "        print(\"{}: {}\".format(self.model.metrics_names[0], scores[0]))\n",
    "        print(\"{}: {}%\".format(self.model.metrics_names[1], scores[1]*100))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_16 (Dense)             (None, 8)                 40        \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 5)                 45        \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 3)                 18        \n",
      "=================================================================\n",
      "Total params: 163\n",
      "Trainable params: 163\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "120/120 [==============================] - 1s 6ms/step - loss: 1.1022 - acc: 0.3500\n",
      "Epoch 2/30\n",
      "120/120 [==============================] - 0s 124us/step - loss: 1.0880 - acc: 0.4667\n",
      "Epoch 3/30\n",
      "120/120 [==============================] - 0s 135us/step - loss: 1.0875 - acc: 0.4833\n",
      "Epoch 4/30\n",
      "120/120 [==============================] - 0s 130us/step - loss: 1.0876 - acc: 0.4833\n",
      "Epoch 5/30\n",
      "120/120 [==============================] - 0s 114us/step - loss: 1.0863 - acc: 0.5000\n",
      "Epoch 6/30\n",
      "120/120 [==============================] - 0s 116us/step - loss: 1.0836 - acc: 0.5083\n",
      "Epoch 7/30\n",
      "120/120 [==============================] - 0s 133us/step - loss: 1.0816 - acc: 0.4917\n",
      "Epoch 8/30\n",
      "120/120 [==============================] - 0s 160us/step - loss: 1.0812 - acc: 0.4583\n",
      "Epoch 9/30\n",
      "120/120 [==============================] - 0s 146us/step - loss: 1.0775 - acc: 0.4500\n",
      "Epoch 10/30\n",
      "120/120 [==============================] - 0s 142us/step - loss: 1.0748 - acc: 0.4917\n",
      "Epoch 11/30\n",
      "120/120 [==============================] - 0s 153us/step - loss: 1.0726 - acc: 0.8083\n",
      "Epoch 12/30\n",
      "120/120 [==============================] - 0s 132us/step - loss: 1.0706 - acc: 0.7667\n",
      "Epoch 13/30\n",
      "120/120 [==============================] - 0s 161us/step - loss: 1.0682 - acc: 0.6667\n",
      "Epoch 14/30\n",
      "120/120 [==============================] - 0s 126us/step - loss: 1.0653 - acc: 0.6833\n",
      "Epoch 15/30\n",
      "120/120 [==============================] - 0s 154us/step - loss: 1.0622 - acc: 0.7250\n",
      "Epoch 16/30\n",
      "120/120 [==============================] - 0s 151us/step - loss: 1.0591 - acc: 0.7667\n",
      "Epoch 17/30\n",
      "120/120 [==============================] - 0s 153us/step - loss: 1.0556 - acc: 0.7750\n",
      "Epoch 18/30\n",
      "120/120 [==============================] - 0s 156us/step - loss: 1.0522 - acc: 0.7833\n",
      "Epoch 19/30\n",
      "120/120 [==============================] - 0s 195us/step - loss: 1.0482 - acc: 0.7500\n",
      "Epoch 20/30\n",
      "120/120 [==============================] - 0s 163us/step - loss: 1.0445 - acc: 0.7000\n",
      "Epoch 21/30\n",
      "120/120 [==============================] - 0s 171us/step - loss: 1.0397 - acc: 0.7000\n",
      "Epoch 22/30\n",
      "120/120 [==============================] - 0s 174us/step - loss: 1.0357 - acc: 0.7000\n",
      "Epoch 23/30\n",
      "120/120 [==============================] - 0s 168us/step - loss: 1.0302 - acc: 0.6833\n",
      "Epoch 24/30\n",
      "120/120 [==============================] - 0s 163us/step - loss: 1.0250 - acc: 0.6750\n",
      "Epoch 25/30\n",
      "120/120 [==============================] - 0s 145us/step - loss: 1.0191 - acc: 0.6500\n",
      "Epoch 26/30\n",
      "120/120 [==============================] - 0s 150us/step - loss: 1.0135 - acc: 0.6500\n",
      "Epoch 27/30\n",
      "120/120 [==============================] - 0s 142us/step - loss: 1.0073 - acc: 0.6583\n",
      "Epoch 28/30\n",
      "120/120 [==============================] - 0s 154us/step - loss: 1.0002 - acc: 0.6500\n",
      "Epoch 29/30\n",
      "120/120 [==============================] - 0s 166us/step - loss: 0.9935 - acc: 0.6417\n",
      "Epoch 30/30\n",
      "120/120 [==============================] - 0s 162us/step - loss: 0.9861 - acc: 0.6500\n",
      "{'batch_size': 32, 'epochs': 30, 'steps': None, 'samples': 120, 'verbose': 1, 'do_validation': False, 'metrics': ['loss', 'acc']}\n",
      "{'loss': [1.1021719932556153, 1.0880176464716593, 1.087521529197693, 1.0875535488128663, 1.0863474289576212, 1.0836270332336426, 1.0815929969151814, 1.0811755100886027, 1.0775028864542644, 1.074761970837911, 1.0725861231486002, 1.070591115951538, 1.0681796709696452, 1.0652560790379841, 1.062241268157959, 1.059099539120992, 1.0556105613708495, 1.052176054318746, 1.0482447385787963, 1.0445087432861329, 1.0397169828414916, 1.0357090950012207, 1.0301507472991944, 1.0250253597895305, 1.0191423813501994, 1.0134850025177002, 1.0072896083196003, 1.0002384185791016, 0.9934564749399821, 0.9860996921857198], 'acc': [0.3500000019868215, 0.46666666865348816, 0.48333333333333334, 0.48333333134651185, 0.4999999980131785, 0.5083333333333333, 0.49166667064030967, 0.4583333353201548, 0.4500000019868215, 0.49166667064030967, 0.8083333373069763, 0.7666666666666667, 0.6666666666666666, 0.6833333293596904, 0.725000003973643, 0.7666666626930236, 0.774999996026357, 0.7833333333333333, 0.750000003973643, 0.699999996026357, 0.700000003973643, 0.699999996026357, 0.6833333293596904, 0.675000003973643, 0.649999996026357, 0.649999996026357, 0.6583333333333333, 0.649999996026357, 0.6416666666666667, 0.65]}\n",
      "30/30 [==============================] - 0s 5ms/step\n",
      "loss: 0.9611425995826721\n",
      "acc: 69.9999988079071%\n"
     ]
    }
   ],
   "source": [
    "NN = KerasNeuralNetwork(x_train, y_train, x_test, y_test)\n",
    "NN.run()\n",
    "NN.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
