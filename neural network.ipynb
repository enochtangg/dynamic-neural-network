{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Import all packages and libraries for NN\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.utils import shuffle\n",
    "from keras.utils import np_utils\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "\n",
    "import keras\n",
    "import pandas\n",
    "import numpy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Processing\n",
    "# Preparing Iris dataset for usage as a dataframe\n",
    "# Encoding output variables\n",
    "# Shuffle rows randomly for variety\n",
    "# Spliting dataset to test and train dataframes. Test dataset will be 80% of entire dataframe.\n",
    "# Parsing dataframe to features and labels (x_train and y_train)\n",
    "\n",
    "# Constants\n",
    "_training_split = 0.8\n",
    "\n",
    "\n",
    "# Load in dataset\n",
    "# Turning training dataframe to x_train and encoded y_train\n",
    "df = pandas.read_csv('iris.csv')\n",
    "df = shuffle(df)\n",
    "features = list(df.columns.values)[:-1]\n",
    "labels = list(df.columns.values)[-1]\n",
    "input_dim = len(list(df.columns.values)[:-1])\n",
    "\n",
    "\n",
    "# Spliting dataframe to training and testing\n",
    "def split_to_training(dataframe):\n",
    "    train_df = dataframe[:int(len(dataframe)*_training_split)]\n",
    "    \n",
    "    return train_df\n",
    "\n",
    "\n",
    "def split_to_testing(dataframe):\n",
    "    test_df = dataframe[int(len(dataframe)*_training_split):]\n",
    "    \n",
    "    return test_df\n",
    "\n",
    "\n",
    "# Spliting training or testing dataset to x and y\n",
    "def split_to_x(dataframe):\n",
    "    x = dataframe[features].values\n",
    "    \n",
    "    return x\n",
    "\n",
    "\n",
    "def split_to_y(dataframe):\n",
    "    y = dataframe[labels].values\n",
    "    \n",
    "    return y\n",
    "\n",
    "\n",
    "# Encoding all labels with HOT Encoder\n",
    "def encode_labels(label_dataframe):\n",
    "    encoder = LabelEncoder()\n",
    "    encoder.fit(label_dataframe)\n",
    "    encoded_y = encoder.transform(label_dataframe)\n",
    "    new_y = np_utils.to_categorical(encoded_y)\n",
    "    \n",
    "    return new_y\n",
    "\n",
    "\n",
    "train_df = split_to_training(df)\n",
    "x_train = split_to_x(train_df)\n",
    "y_train = encode_labels(split_to_y(train_df))\n",
    "\n",
    "test_df = split_to_testing(df)\n",
    "x_test = split_to_x(test_df)\n",
    "y_test = encode_labels(split_to_y(test_df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KerasNeuralNetwork:\n",
    "    def __init__(self, x_train, y_train, x_test, y_test):\n",
    "        self.x_train = x_train\n",
    "        self.y_train = y_train\n",
    "        self.x_test = x_test\n",
    "        self.y_test = y_test\n",
    "        self.model = Sequential()\n",
    "        \n",
    "        \n",
    "    def run(self):\n",
    "        self.model.add(Dense(8, input_dim=input_dim, activation='relu'))\n",
    "        self.model.add(Dense(3, activation='softmax'))\n",
    "        self.model.summary()\n",
    "        \n",
    "        self.model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "        \n",
    "        history = self.model.fit(self.x_train, self.y_train, epochs=500)\n",
    "        print(history.params)\n",
    "        print(history.history)\n",
    "\n",
    "        \n",
    "    def evaluate(self):\n",
    "        scores = self.model.evaluate(self.x_test, self.y_test, batch_size=128)\n",
    "        print(\"{}: {}%\".format(self.model.metrics_names[1], scores[1]*100))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 8)                 40        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 27        \n",
      "=================================================================\n",
      "Total params: 67\n",
      "Trainable params: 67\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/500\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 2.9505 - acc: 0.3500\n",
      "Epoch 2/500\n",
      "120/120 [==============================] - 0s 83us/step - loss: 2.8381 - acc: 0.3500\n",
      "Epoch 3/500\n",
      "120/120 [==============================] - 0s 119us/step - loss: 2.7302 - acc: 0.3500\n",
      "Epoch 4/500\n",
      "120/120 [==============================] - 0s 83us/step - loss: 2.6218 - acc: 0.3500\n",
      "Epoch 5/500\n",
      "120/120 [==============================] - 0s 87us/step - loss: 2.5199 - acc: 0.3500\n",
      "Epoch 6/500\n",
      "120/120 [==============================] - 0s 91us/step - loss: 2.4279 - acc: 0.3500\n",
      "Epoch 7/500\n",
      "120/120 [==============================] - 0s 96us/step - loss: 2.3388 - acc: 0.3500\n",
      "Epoch 8/500\n",
      "120/120 [==============================] - 0s 127us/step - loss: 2.2512 - acc: 0.3500\n",
      "Epoch 9/500\n",
      "120/120 [==============================] - 0s 100us/step - loss: 2.1728 - acc: 0.3500\n",
      "Epoch 10/500\n",
      "120/120 [==============================] - 0s 92us/step - loss: 2.0981 - acc: 0.3500\n",
      "Epoch 11/500\n",
      "120/120 [==============================] - 0s 87us/step - loss: 2.0303 - acc: 0.3500\n",
      "Epoch 12/500\n",
      "120/120 [==============================] - 0s 116us/step - loss: 1.9623 - acc: 0.3500\n",
      "Epoch 13/500\n",
      "120/120 [==============================] - 0s 126us/step - loss: 1.9029 - acc: 0.3500\n",
      "Epoch 14/500\n",
      "120/120 [==============================] - 0s 118us/step - loss: 1.8516 - acc: 0.3500\n",
      "Epoch 15/500\n",
      "120/120 [==============================] - 0s 101us/step - loss: 1.7945 - acc: 0.3500\n",
      "Epoch 16/500\n",
      "120/120 [==============================] - 0s 117us/step - loss: 1.7489 - acc: 0.3500\n",
      "Epoch 17/500\n",
      "120/120 [==============================] - 0s 116us/step - loss: 1.7059 - acc: 0.3500\n",
      "Epoch 18/500\n",
      "120/120 [==============================] - 0s 118us/step - loss: 1.6653 - acc: 0.3500\n",
      "Epoch 19/500\n",
      "120/120 [==============================] - 0s 112us/step - loss: 1.6268 - acc: 0.3500\n",
      "Epoch 20/500\n",
      "120/120 [==============================] - 0s 113us/step - loss: 1.5906 - acc: 0.3500\n",
      "Epoch 21/500\n",
      "120/120 [==============================] - 0s 108us/step - loss: 1.5588 - acc: 0.3500\n",
      "Epoch 22/500\n",
      "120/120 [==============================] - 0s 112us/step - loss: 1.5283 - acc: 0.3500\n",
      "Epoch 23/500\n",
      "120/120 [==============================] - 0s 123us/step - loss: 1.5003 - acc: 0.3500\n",
      "Epoch 24/500\n",
      "120/120 [==============================] - 0s 114us/step - loss: 1.4724 - acc: 0.3500\n",
      "Epoch 25/500\n",
      "120/120 [==============================] - 0s 119us/step - loss: 1.4470 - acc: 0.3500\n",
      "Epoch 26/500\n",
      "120/120 [==============================] - 0s 100us/step - loss: 1.4245 - acc: 0.3500\n",
      "Epoch 27/500\n",
      "120/120 [==============================] - 0s 116us/step - loss: 1.4006 - acc: 0.3500\n",
      "Epoch 28/500\n",
      "120/120 [==============================] - 0s 96us/step - loss: 1.3795 - acc: 0.3500\n",
      "Epoch 29/500\n",
      "120/120 [==============================] - 0s 96us/step - loss: 1.3607 - acc: 0.3500\n",
      "Epoch 30/500\n",
      "120/120 [==============================] - 0s 111us/step - loss: 1.3422 - acc: 0.3500\n",
      "Epoch 31/500\n",
      "120/120 [==============================] - 0s 106us/step - loss: 1.3248 - acc: 0.3500\n",
      "Epoch 32/500\n",
      "120/120 [==============================] - 0s 108us/step - loss: 1.3071 - acc: 0.3500\n",
      "Epoch 33/500\n",
      "120/120 [==============================] - 0s 112us/step - loss: 1.2929 - acc: 0.3500\n",
      "Epoch 34/500\n",
      "120/120 [==============================] - 0s 131us/step - loss: 1.2781 - acc: 0.3500\n",
      "Epoch 35/500\n",
      "120/120 [==============================] - 0s 107us/step - loss: 1.2641 - acc: 0.3500\n",
      "Epoch 36/500\n",
      "120/120 [==============================] - 0s 122us/step - loss: 1.2514 - acc: 0.3500\n",
      "Epoch 37/500\n",
      "120/120 [==============================] - 0s 91us/step - loss: 1.2406 - acc: 0.3500\n",
      "Epoch 38/500\n",
      "120/120 [==============================] - 0s 103us/step - loss: 1.2269 - acc: 0.3500\n",
      "Epoch 39/500\n",
      "120/120 [==============================] - 0s 106us/step - loss: 1.2171 - acc: 0.3500\n",
      "Epoch 40/500\n",
      "120/120 [==============================] - 0s 121us/step - loss: 1.2074 - acc: 0.3500\n",
      "Epoch 41/500\n",
      "120/120 [==============================] - 0s 101us/step - loss: 1.1983 - acc: 0.3500\n",
      "Epoch 42/500\n",
      "120/120 [==============================] - 0s 110us/step - loss: 1.1891 - acc: 0.3500\n",
      "Epoch 43/500\n",
      "120/120 [==============================] - 0s 98us/step - loss: 1.1809 - acc: 0.3500\n",
      "Epoch 44/500\n",
      "120/120 [==============================] - 0s 136us/step - loss: 1.1737 - acc: 0.3500\n",
      "Epoch 45/500\n",
      "120/120 [==============================] - 0s 108us/step - loss: 1.1668 - acc: 0.3667\n",
      "Epoch 46/500\n",
      "120/120 [==============================] - 0s 125us/step - loss: 1.1595 - acc: 0.3667\n",
      "Epoch 47/500\n",
      "120/120 [==============================] - 0s 101us/step - loss: 1.1536 - acc: 0.3583\n",
      "Epoch 48/500\n",
      "120/120 [==============================] - 0s 121us/step - loss: 1.1475 - acc: 0.3417\n",
      "Epoch 49/500\n",
      "120/120 [==============================] - 0s 119us/step - loss: 1.1426 - acc: 0.3000\n",
      "Epoch 50/500\n",
      "120/120 [==============================] - 0s 109us/step - loss: 1.1372 - acc: 0.2417\n",
      "Epoch 51/500\n",
      "120/120 [==============================] - 0s 96us/step - loss: 1.1322 - acc: 0.1917\n",
      "Epoch 52/500\n",
      "120/120 [==============================] - 0s 142us/step - loss: 1.1276 - acc: 0.1417\n",
      "Epoch 53/500\n",
      "120/120 [==============================] - 0s 120us/step - loss: 1.1239 - acc: 0.1417\n",
      "Epoch 54/500\n",
      "120/120 [==============================] - 0s 120us/step - loss: 1.1200 - acc: 0.1667\n",
      "Epoch 55/500\n",
      "120/120 [==============================] - 0s 131us/step - loss: 1.1158 - acc: 0.1917\n",
      "Epoch 56/500\n",
      "120/120 [==============================] - 0s 105us/step - loss: 1.1125 - acc: 0.2000\n",
      "Epoch 57/500\n",
      "120/120 [==============================] - 0s 130us/step - loss: 1.1092 - acc: 0.2167\n",
      "Epoch 58/500\n",
      "120/120 [==============================] - 0s 111us/step - loss: 1.1060 - acc: 0.2333\n",
      "Epoch 59/500\n",
      "120/120 [==============================] - 0s 104us/step - loss: 1.1033 - acc: 0.2667\n",
      "Epoch 60/500\n",
      "120/120 [==============================] - 0s 113us/step - loss: 1.1009 - acc: 0.2917\n",
      "Epoch 61/500\n",
      "120/120 [==============================] - 0s 97us/step - loss: 1.0976 - acc: 0.3750\n",
      "Epoch 62/500\n",
      "120/120 [==============================] - 0s 99us/step - loss: 1.0956 - acc: 0.4250\n",
      "Epoch 63/500\n",
      "120/120 [==============================] - 0s 107us/step - loss: 1.0932 - acc: 0.4083\n",
      "Epoch 64/500\n",
      "120/120 [==============================] - 0s 93us/step - loss: 1.0910 - acc: 0.4167\n",
      "Epoch 65/500\n",
      "120/120 [==============================] - 0s 109us/step - loss: 1.0891 - acc: 0.4250\n",
      "Epoch 66/500\n",
      "120/120 [==============================] - 0s 96us/step - loss: 1.0870 - acc: 0.4333\n",
      "Epoch 67/500\n",
      "120/120 [==============================] - 0s 104us/step - loss: 1.0852 - acc: 0.4333\n",
      "Epoch 68/500\n",
      "120/120 [==============================] - 0s 92us/step - loss: 1.0833 - acc: 0.4333\n",
      "Epoch 69/500\n",
      "120/120 [==============================] - 0s 103us/step - loss: 1.0817 - acc: 0.4333\n",
      "Epoch 70/500\n",
      "120/120 [==============================] - 0s 96us/step - loss: 1.0803 - acc: 0.4250\n",
      "Epoch 71/500\n",
      "120/120 [==============================] - 0s 102us/step - loss: 1.0786 - acc: 0.4250\n",
      "Epoch 72/500\n",
      "120/120 [==============================] - 0s 104us/step - loss: 1.0773 - acc: 0.4167\n",
      "Epoch 73/500\n",
      "120/120 [==============================] - 0s 96us/step - loss: 1.0756 - acc: 0.4167\n",
      "Epoch 74/500\n",
      "120/120 [==============================] - 0s 113us/step - loss: 1.0741 - acc: 0.3917\n",
      "Epoch 75/500\n",
      "120/120 [==============================] - 0s 92us/step - loss: 1.0729 - acc: 0.3917\n",
      "Epoch 76/500\n",
      "120/120 [==============================] - 0s 108us/step - loss: 1.0717 - acc: 0.4000\n",
      "Epoch 77/500\n",
      "120/120 [==============================] - 0s 98us/step - loss: 1.0705 - acc: 0.3917\n",
      "Epoch 78/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 0s 120us/step - loss: 1.0693 - acc: 0.3917\n",
      "Epoch 79/500\n",
      "120/120 [==============================] - 0s 99us/step - loss: 1.0682 - acc: 0.3917\n",
      "Epoch 80/500\n",
      "120/120 [==============================] - 0s 113us/step - loss: 1.0671 - acc: 0.4000\n",
      "Epoch 81/500\n",
      "120/120 [==============================] - 0s 98us/step - loss: 1.0657 - acc: 0.4083\n",
      "Epoch 82/500\n",
      "120/120 [==============================] - 0s 117us/step - loss: 1.0649 - acc: 0.4000\n",
      "Epoch 83/500\n",
      "120/120 [==============================] - 0s 117us/step - loss: 1.0639 - acc: 0.4000\n",
      "Epoch 84/500\n",
      "120/120 [==============================] - 0s 111us/step - loss: 1.0627 - acc: 0.4083\n",
      "Epoch 85/500\n",
      "120/120 [==============================] - 0s 119us/step - loss: 1.0618 - acc: 0.4000\n",
      "Epoch 86/500\n",
      "120/120 [==============================] - 0s 116us/step - loss: 1.0607 - acc: 0.4000\n",
      "Epoch 87/500\n",
      "120/120 [==============================] - 0s 98us/step - loss: 1.0597 - acc: 0.4000\n",
      "Epoch 88/500\n",
      "120/120 [==============================] - 0s 118us/step - loss: 1.0588 - acc: 0.3917\n",
      "Epoch 89/500\n",
      "120/120 [==============================] - 0s 101us/step - loss: 1.0579 - acc: 0.3917\n",
      "Epoch 90/500\n",
      "120/120 [==============================] - 0s 106us/step - loss: 1.0569 - acc: 0.3917\n",
      "Epoch 91/500\n",
      "120/120 [==============================] - 0s 118us/step - loss: 1.0567 - acc: 0.3750\n",
      "Epoch 92/500\n",
      "120/120 [==============================] - 0s 144us/step - loss: 1.0552 - acc: 0.3750\n",
      "Epoch 93/500\n",
      "120/120 [==============================] - 0s 122us/step - loss: 1.0542 - acc: 0.3917\n",
      "Epoch 94/500\n",
      "120/120 [==============================] - 0s 171us/step - loss: 1.0533 - acc: 0.4083\n",
      "Epoch 95/500\n",
      "120/120 [==============================] - 0s 111us/step - loss: 1.0524 - acc: 0.3917\n",
      "Epoch 96/500\n",
      "120/120 [==============================] - 0s 127us/step - loss: 1.0516 - acc: 0.3917\n",
      "Epoch 97/500\n",
      "120/120 [==============================] - 0s 151us/step - loss: 1.0507 - acc: 0.3833\n",
      "Epoch 98/500\n",
      "120/120 [==============================] - 0s 122us/step - loss: 1.0498 - acc: 0.3667\n",
      "Epoch 99/500\n",
      "120/120 [==============================] - 0s 144us/step - loss: 1.0489 - acc: 0.3667\n",
      "Epoch 100/500\n",
      "120/120 [==============================] - 0s 111us/step - loss: 1.0481 - acc: 0.3667\n",
      "Epoch 101/500\n",
      "120/120 [==============================] - 0s 108us/step - loss: 1.0472 - acc: 0.3667\n",
      "Epoch 102/500\n",
      "120/120 [==============================] - 0s 108us/step - loss: 1.0464 - acc: 0.3667\n",
      "Epoch 103/500\n",
      "120/120 [==============================] - 0s 127us/step - loss: 1.0457 - acc: 0.3500\n",
      "Epoch 104/500\n",
      "120/120 [==============================] - 0s 116us/step - loss: 1.0446 - acc: 0.3667\n",
      "Epoch 105/500\n",
      "120/120 [==============================] - 0s 126us/step - loss: 1.0438 - acc: 0.3667\n",
      "Epoch 106/500\n",
      "120/120 [==============================] - 0s 129us/step - loss: 1.0430 - acc: 0.3667\n",
      "Epoch 107/500\n",
      "120/120 [==============================] - 0s 135us/step - loss: 1.0419 - acc: 0.3667\n",
      "Epoch 108/500\n",
      "120/120 [==============================] - 0s 138us/step - loss: 1.0412 - acc: 0.3667\n",
      "Epoch 109/500\n",
      "120/120 [==============================] - 0s 113us/step - loss: 1.0404 - acc: 0.3833\n",
      "Epoch 110/500\n",
      "120/120 [==============================] - 0s 121us/step - loss: 1.0394 - acc: 0.3833\n",
      "Epoch 111/500\n",
      "120/120 [==============================] - 0s 123us/step - loss: 1.0385 - acc: 0.3833\n",
      "Epoch 112/500\n",
      "120/120 [==============================] - 0s 130us/step - loss: 1.0377 - acc: 0.3667\n",
      "Epoch 113/500\n",
      "120/120 [==============================] - 0s 125us/step - loss: 1.0368 - acc: 0.3667\n",
      "Epoch 114/500\n",
      "120/120 [==============================] - 0s 116us/step - loss: 1.0361 - acc: 0.3583\n",
      "Epoch 115/500\n",
      "120/120 [==============================] - 0s 104us/step - loss: 1.0351 - acc: 0.3667\n",
      "Epoch 116/500\n",
      "120/120 [==============================] - 0s 120us/step - loss: 1.0341 - acc: 0.3667\n",
      "Epoch 117/500\n",
      "120/120 [==============================] - 0s 121us/step - loss: 1.0331 - acc: 0.3667\n",
      "Epoch 118/500\n",
      "120/120 [==============================] - 0s 106us/step - loss: 1.0325 - acc: 0.3583\n",
      "Epoch 119/500\n",
      "120/120 [==============================] - 0s 110us/step - loss: 1.0314 - acc: 0.3583\n",
      "Epoch 120/500\n",
      "120/120 [==============================] - 0s 104us/step - loss: 1.0304 - acc: 0.3583\n",
      "Epoch 121/500\n",
      "120/120 [==============================] - 0s 118us/step - loss: 1.0295 - acc: 0.3583\n",
      "Epoch 122/500\n",
      "120/120 [==============================] - 0s 130us/step - loss: 1.0286 - acc: 0.3667\n",
      "Epoch 123/500\n",
      "120/120 [==============================] - 0s 112us/step - loss: 1.0277 - acc: 0.3667\n",
      "Epoch 124/500\n",
      "120/120 [==============================] - 0s 114us/step - loss: 1.0269 - acc: 0.3667\n",
      "Epoch 125/500\n",
      "120/120 [==============================] - 0s 139us/step - loss: 1.0257 - acc: 0.3667\n",
      "Epoch 126/500\n",
      "120/120 [==============================] - 0s 127us/step - loss: 1.0248 - acc: 0.3667\n",
      "Epoch 127/500\n",
      "120/120 [==============================] - 0s 115us/step - loss: 1.0238 - acc: 0.3667\n",
      "Epoch 128/500\n",
      "120/120 [==============================] - 0s 115us/step - loss: 1.0231 - acc: 0.3583\n",
      "Epoch 129/500\n",
      "120/120 [==============================] - 0s 129us/step - loss: 1.0224 - acc: 0.3583\n",
      "Epoch 130/500\n",
      "120/120 [==============================] - 0s 106us/step - loss: 1.0210 - acc: 0.3583\n",
      "Epoch 131/500\n",
      "120/120 [==============================] - 0s 101us/step - loss: 1.0200 - acc: 0.3583\n",
      "Epoch 132/500\n",
      "120/120 [==============================] - 0s 104us/step - loss: 1.0191 - acc: 0.3583\n",
      "Epoch 133/500\n",
      "120/120 [==============================] - 0s 88us/step - loss: 1.0180 - acc: 0.3500\n",
      "Epoch 134/500\n",
      "120/120 [==============================] - 0s 86us/step - loss: 1.0170 - acc: 0.3333\n",
      "Epoch 135/500\n",
      "120/120 [==============================] - 0s 85us/step - loss: 1.0160 - acc: 0.3417\n",
      "Epoch 136/500\n",
      "120/120 [==============================] - 0s 79us/step - loss: 1.0150 - acc: 0.3583\n",
      "Epoch 137/500\n",
      "120/120 [==============================] - 0s 77us/step - loss: 1.0139 - acc: 0.3583\n",
      "Epoch 138/500\n",
      "120/120 [==============================] - 0s 87us/step - loss: 1.0129 - acc: 0.3667\n",
      "Epoch 139/500\n",
      "120/120 [==============================] - 0s 71us/step - loss: 1.0119 - acc: 0.3667\n",
      "Epoch 140/500\n",
      "120/120 [==============================] - 0s 74us/step - loss: 1.0108 - acc: 0.3667\n",
      "Epoch 141/500\n",
      "120/120 [==============================] - 0s 70us/step - loss: 1.0098 - acc: 0.3667\n",
      "Epoch 142/500\n",
      "120/120 [==============================] - 0s 78us/step - loss: 1.0087 - acc: 0.3667\n",
      "Epoch 143/500\n",
      "120/120 [==============================] - 0s 69us/step - loss: 1.0076 - acc: 0.3667\n",
      "Epoch 144/500\n",
      "120/120 [==============================] - 0s 85us/step - loss: 1.0065 - acc: 0.3667\n",
      "Epoch 145/500\n",
      "120/120 [==============================] - 0s 72us/step - loss: 1.0054 - acc: 0.3583\n",
      "Epoch 146/500\n",
      "120/120 [==============================] - 0s 73us/step - loss: 1.0044 - acc: 0.3583\n",
      "Epoch 147/500\n",
      "120/120 [==============================] - 0s 76us/step - loss: 1.0034 - acc: 0.3500\n",
      "Epoch 148/500\n",
      "120/120 [==============================] - 0s 70us/step - loss: 1.0022 - acc: 0.3333\n",
      "Epoch 149/500\n",
      "120/120 [==============================] - 0s 84us/step - loss: 1.0011 - acc: 0.3333\n",
      "Epoch 150/500\n",
      "120/120 [==============================] - 0s 83us/step - loss: 0.9998 - acc: 0.3500\n",
      "Epoch 151/500\n",
      "120/120 [==============================] - 0s 84us/step - loss: 0.9989 - acc: 0.3667\n",
      "Epoch 152/500\n",
      "120/120 [==============================] - 0s 76us/step - loss: 0.9976 - acc: 0.3667\n",
      "Epoch 153/500\n",
      "120/120 [==============================] - 0s 67us/step - loss: 0.9964 - acc: 0.3667\n",
      "Epoch 154/500\n",
      "120/120 [==============================] - 0s 74us/step - loss: 0.9953 - acc: 0.3667\n",
      "Epoch 155/500\n",
      "120/120 [==============================] - 0s 79us/step - loss: 0.9940 - acc: 0.3667\n",
      "Epoch 156/500\n",
      "120/120 [==============================] - 0s 73us/step - loss: 0.9929 - acc: 0.3667\n",
      "Epoch 157/500\n",
      "120/120 [==============================] - 0s 74us/step - loss: 0.9917 - acc: 0.3667\n",
      "Epoch 158/500\n",
      "120/120 [==============================] - 0s 74us/step - loss: 0.9905 - acc: 0.3667\n",
      "Epoch 159/500\n",
      "120/120 [==============================] - 0s 77us/step - loss: 0.9893 - acc: 0.3667\n",
      "Epoch 160/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 0s 93us/step - loss: 0.9881 - acc: 0.3667\n",
      "Epoch 161/500\n",
      "120/120 [==============================] - 0s 91us/step - loss: 0.9868 - acc: 0.3667\n",
      "Epoch 162/500\n",
      "120/120 [==============================] - 0s 117us/step - loss: 0.9857 - acc: 0.3750\n",
      "Epoch 163/500\n",
      "120/120 [==============================] - 0s 94us/step - loss: 0.9842 - acc: 0.3750\n",
      "Epoch 164/500\n",
      "120/120 [==============================] - 0s 102us/step - loss: 0.9832 - acc: 0.3750\n",
      "Epoch 165/500\n",
      "120/120 [==============================] - 0s 84us/step - loss: 0.9816 - acc: 0.3667\n",
      "Epoch 166/500\n",
      "120/120 [==============================] - 0s 90us/step - loss: 0.9804 - acc: 0.3667\n",
      "Epoch 167/500\n",
      "120/120 [==============================] - 0s 102us/step - loss: 0.9790 - acc: 0.3583\n",
      "Epoch 168/500\n",
      "120/120 [==============================] - 0s 91us/step - loss: 0.9779 - acc: 0.3667\n",
      "Epoch 169/500\n",
      "120/120 [==============================] - 0s 86us/step - loss: 0.9764 - acc: 0.3667\n",
      "Epoch 170/500\n",
      "120/120 [==============================] - 0s 98us/step - loss: 0.9752 - acc: 0.3583\n",
      "Epoch 171/500\n",
      "120/120 [==============================] - 0s 99us/step - loss: 0.9739 - acc: 0.3583\n",
      "Epoch 172/500\n",
      "120/120 [==============================] - 0s 99us/step - loss: 0.9726 - acc: 0.3583\n",
      "Epoch 173/500\n",
      "120/120 [==============================] - 0s 103us/step - loss: 0.9711 - acc: 0.3667\n",
      "Epoch 174/500\n",
      "120/120 [==============================] - 0s 104us/step - loss: 0.9697 - acc: 0.3667\n",
      "Epoch 175/500\n",
      "120/120 [==============================] - 0s 110us/step - loss: 0.9683 - acc: 0.3750\n",
      "Epoch 176/500\n",
      "120/120 [==============================] - 0s 99us/step - loss: 0.9669 - acc: 0.3750\n",
      "Epoch 177/500\n",
      "120/120 [==============================] - 0s 85us/step - loss: 0.9655 - acc: 0.3750\n",
      "Epoch 178/500\n",
      "120/120 [==============================] - 0s 83us/step - loss: 0.9640 - acc: 0.3750\n",
      "Epoch 179/500\n",
      "120/120 [==============================] - 0s 77us/step - loss: 0.9626 - acc: 0.3667\n",
      "Epoch 180/500\n",
      "120/120 [==============================] - 0s 83us/step - loss: 0.9613 - acc: 0.3833\n",
      "Epoch 181/500\n",
      "120/120 [==============================] - 0s 90us/step - loss: 0.9598 - acc: 0.3833\n",
      "Epoch 182/500\n",
      "120/120 [==============================] - 0s 101us/step - loss: 0.9582 - acc: 0.3833\n",
      "Epoch 183/500\n",
      "120/120 [==============================] - 0s 84us/step - loss: 0.9567 - acc: 0.3833\n",
      "Epoch 184/500\n",
      "120/120 [==============================] - 0s 74us/step - loss: 0.9552 - acc: 0.3833\n",
      "Epoch 185/500\n",
      "120/120 [==============================] - 0s 76us/step - loss: 0.9539 - acc: 0.3667\n",
      "Epoch 186/500\n",
      "120/120 [==============================] - 0s 78us/step - loss: 0.9521 - acc: 0.3667\n",
      "Epoch 187/500\n",
      "120/120 [==============================] - 0s 65us/step - loss: 0.9505 - acc: 0.3583\n",
      "Epoch 188/500\n",
      "120/120 [==============================] - 0s 64us/step - loss: 0.9490 - acc: 0.3583\n",
      "Epoch 189/500\n",
      "120/120 [==============================] - 0s 76us/step - loss: 0.9473 - acc: 0.3667\n",
      "Epoch 190/500\n",
      "120/120 [==============================] - 0s 84us/step - loss: 0.9459 - acc: 0.3667\n",
      "Epoch 191/500\n",
      "120/120 [==============================] - 0s 69us/step - loss: 0.9443 - acc: 0.3750\n",
      "Epoch 192/500\n",
      "120/120 [==============================] - 0s 86us/step - loss: 0.9430 - acc: 0.3833\n",
      "Epoch 193/500\n",
      "120/120 [==============================] - 0s 73us/step - loss: 0.9410 - acc: 0.3750\n",
      "Epoch 194/500\n",
      "120/120 [==============================] - 0s 73us/step - loss: 0.9392 - acc: 0.3750\n",
      "Epoch 195/500\n",
      "120/120 [==============================] - 0s 73us/step - loss: 0.9378 - acc: 0.3667\n",
      "Epoch 196/500\n",
      "120/120 [==============================] - 0s 87us/step - loss: 0.9365 - acc: 0.3667\n",
      "Epoch 197/500\n",
      "120/120 [==============================] - 0s 86us/step - loss: 0.9342 - acc: 0.3667\n",
      "Epoch 198/500\n",
      "120/120 [==============================] - 0s 80us/step - loss: 0.9326 - acc: 0.3667\n",
      "Epoch 199/500\n",
      "120/120 [==============================] - 0s 79us/step - loss: 0.9307 - acc: 0.3667\n",
      "Epoch 200/500\n",
      "120/120 [==============================] - 0s 84us/step - loss: 0.9291 - acc: 0.3667\n",
      "Epoch 201/500\n",
      "120/120 [==============================] - 0s 86us/step - loss: 0.9273 - acc: 0.3667\n",
      "Epoch 202/500\n",
      "120/120 [==============================] - 0s 100us/step - loss: 0.9254 - acc: 0.3667\n",
      "Epoch 203/500\n",
      "120/120 [==============================] - 0s 101us/step - loss: 0.9237 - acc: 0.3750\n",
      "Epoch 204/500\n",
      "120/120 [==============================] - 0s 96us/step - loss: 0.9220 - acc: 0.3750\n",
      "Epoch 205/500\n",
      "120/120 [==============================] - 0s 96us/step - loss: 0.9202 - acc: 0.3750\n",
      "Epoch 206/500\n",
      "120/120 [==============================] - 0s 108us/step - loss: 0.9182 - acc: 0.3750\n",
      "Epoch 207/500\n",
      "120/120 [==============================] - 0s 87us/step - loss: 0.9163 - acc: 0.3833\n",
      "Epoch 208/500\n",
      "120/120 [==============================] - 0s 84us/step - loss: 0.9145 - acc: 0.3917\n",
      "Epoch 209/500\n",
      "120/120 [==============================] - 0s 74us/step - loss: 0.9127 - acc: 0.3833\n",
      "Epoch 210/500\n",
      "120/120 [==============================] - 0s 77us/step - loss: 0.9108 - acc: 0.4000\n",
      "Epoch 211/500\n",
      "120/120 [==============================] - 0s 74us/step - loss: 0.9088 - acc: 0.4083\n",
      "Epoch 212/500\n",
      "120/120 [==============================] - 0s 78us/step - loss: 0.9069 - acc: 0.4083\n",
      "Epoch 213/500\n",
      "120/120 [==============================] - 0s 76us/step - loss: 0.9047 - acc: 0.4167\n",
      "Epoch 214/500\n",
      "120/120 [==============================] - 0s 78us/step - loss: 0.9028 - acc: 0.4250\n",
      "Epoch 215/500\n",
      "120/120 [==============================] - 0s 72us/step - loss: 0.9008 - acc: 0.4500\n",
      "Epoch 216/500\n",
      "120/120 [==============================] - 0s 76us/step - loss: 0.8988 - acc: 0.4500\n",
      "Epoch 217/500\n",
      "120/120 [==============================] - 0s 71us/step - loss: 0.8970 - acc: 0.4667\n",
      "Epoch 218/500\n",
      "120/120 [==============================] - 0s 69us/step - loss: 0.8946 - acc: 0.4833\n",
      "Epoch 219/500\n",
      "120/120 [==============================] - 0s 71us/step - loss: 0.8926 - acc: 0.5167\n",
      "Epoch 220/500\n",
      "120/120 [==============================] - 0s 75us/step - loss: 0.8904 - acc: 0.5583\n",
      "Epoch 221/500\n",
      "120/120 [==============================] - 0s 77us/step - loss: 0.8884 - acc: 0.6167\n",
      "Epoch 222/500\n",
      "120/120 [==============================] - 0s 81us/step - loss: 0.8864 - acc: 0.6500\n",
      "Epoch 223/500\n",
      "120/120 [==============================] - 0s 82us/step - loss: 0.8841 - acc: 0.6583\n",
      "Epoch 224/500\n",
      "120/120 [==============================] - 0s 74us/step - loss: 0.8820 - acc: 0.6500\n",
      "Epoch 225/500\n",
      "120/120 [==============================] - 0s 71us/step - loss: 0.8799 - acc: 0.6500\n",
      "Epoch 226/500\n",
      "120/120 [==============================] - 0s 71us/step - loss: 0.8781 - acc: 0.6583\n",
      "Epoch 227/500\n",
      "120/120 [==============================] - 0s 71us/step - loss: 0.8757 - acc: 0.6667\n",
      "Epoch 228/500\n",
      "120/120 [==============================] - 0s 72us/step - loss: 0.8737 - acc: 0.6750\n",
      "Epoch 229/500\n",
      "120/120 [==============================] - 0s 71us/step - loss: 0.8716 - acc: 0.6917\n",
      "Epoch 230/500\n",
      "120/120 [==============================] - 0s 73us/step - loss: 0.8694 - acc: 0.7000\n",
      "Epoch 231/500\n",
      "120/120 [==============================] - 0s 70us/step - loss: 0.8673 - acc: 0.7000\n",
      "Epoch 232/500\n",
      "120/120 [==============================] - 0s 72us/step - loss: 0.8652 - acc: 0.7167\n",
      "Epoch 233/500\n",
      "120/120 [==============================] - 0s 74us/step - loss: 0.8635 - acc: 0.7250\n",
      "Epoch 234/500\n",
      "120/120 [==============================] - 0s 72us/step - loss: 0.8610 - acc: 0.7417\n",
      "Epoch 235/500\n",
      "120/120 [==============================] - 0s 77us/step - loss: 0.8590 - acc: 0.7333\n",
      "Epoch 236/500\n",
      "120/120 [==============================] - 0s 73us/step - loss: 0.8570 - acc: 0.7250\n",
      "Epoch 237/500\n",
      "120/120 [==============================] - 0s 80us/step - loss: 0.8549 - acc: 0.7250\n",
      "Epoch 238/500\n",
      "120/120 [==============================] - 0s 81us/step - loss: 0.8530 - acc: 0.7250\n",
      "Epoch 239/500\n",
      "120/120 [==============================] - 0s 73us/step - loss: 0.8509 - acc: 0.7250\n",
      "Epoch 240/500\n",
      "120/120 [==============================] - 0s 77us/step - loss: 0.8489 - acc: 0.7250\n",
      "Epoch 241/500\n",
      "120/120 [==============================] - 0s 86us/step - loss: 0.8468 - acc: 0.7333\n",
      "Epoch 242/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 0s 86us/step - loss: 0.8449 - acc: 0.7333\n",
      "Epoch 243/500\n",
      "120/120 [==============================] - 0s 96us/step - loss: 0.8428 - acc: 0.7333\n",
      "Epoch 244/500\n",
      "120/120 [==============================] - 0s 94us/step - loss: 0.8408 - acc: 0.7333\n",
      "Epoch 245/500\n",
      "120/120 [==============================] - 0s 100us/step - loss: 0.8388 - acc: 0.7333\n",
      "Epoch 246/500\n",
      "120/120 [==============================] - 0s 91us/step - loss: 0.8372 - acc: 0.7333\n",
      "Epoch 247/500\n",
      "120/120 [==============================] - 0s 80us/step - loss: 0.8351 - acc: 0.7333\n",
      "Epoch 248/500\n",
      "120/120 [==============================] - 0s 82us/step - loss: 0.8331 - acc: 0.7333\n",
      "Epoch 249/500\n",
      "120/120 [==============================] - 0s 81us/step - loss: 0.8308 - acc: 0.7333\n",
      "Epoch 250/500\n",
      "120/120 [==============================] - 0s 89us/step - loss: 0.8289 - acc: 0.7333\n",
      "Epoch 251/500\n",
      "120/120 [==============================] - 0s 79us/step - loss: 0.8269 - acc: 0.7417\n",
      "Epoch 252/500\n",
      "120/120 [==============================] - 0s 76us/step - loss: 0.8250 - acc: 0.7333\n",
      "Epoch 253/500\n",
      "120/120 [==============================] - 0s 69us/step - loss: 0.8228 - acc: 0.7417\n",
      "Epoch 254/500\n",
      "120/120 [==============================] - 0s 82us/step - loss: 0.8207 - acc: 0.7417\n",
      "Epoch 255/500\n",
      "120/120 [==============================] - 0s 88us/step - loss: 0.8188 - acc: 0.7417\n",
      "Epoch 256/500\n",
      "120/120 [==============================] - 0s 75us/step - loss: 0.8168 - acc: 0.7417\n",
      "Epoch 257/500\n",
      "120/120 [==============================] - 0s 83us/step - loss: 0.8147 - acc: 0.7333\n",
      "Epoch 258/500\n",
      "120/120 [==============================] - 0s 88us/step - loss: 0.8126 - acc: 0.7417\n",
      "Epoch 259/500\n",
      "120/120 [==============================] - 0s 76us/step - loss: 0.8111 - acc: 0.7333\n",
      "Epoch 260/500\n",
      "120/120 [==============================] - 0s 72us/step - loss: 0.8086 - acc: 0.7333\n",
      "Epoch 261/500\n",
      "120/120 [==============================] - 0s 82us/step - loss: 0.8067 - acc: 0.7333\n",
      "Epoch 262/500\n",
      "120/120 [==============================] - 0s 79us/step - loss: 0.8048 - acc: 0.7333\n",
      "Epoch 263/500\n",
      "120/120 [==============================] - 0s 87us/step - loss: 0.8027 - acc: 0.7417\n",
      "Epoch 264/500\n",
      "120/120 [==============================] - 0s 99us/step - loss: 0.8005 - acc: 0.7333\n",
      "Epoch 265/500\n",
      "120/120 [==============================] - 0s 117us/step - loss: 0.7985 - acc: 0.7417\n",
      "Epoch 266/500\n",
      "120/120 [==============================] - 0s 95us/step - loss: 0.7966 - acc: 0.7417\n",
      "Epoch 267/500\n",
      "120/120 [==============================] - 0s 111us/step - loss: 0.7943 - acc: 0.7333\n",
      "Epoch 268/500\n",
      "120/120 [==============================] - 0s 105us/step - loss: 0.7923 - acc: 0.7333\n",
      "Epoch 269/500\n",
      "120/120 [==============================] - 0s 114us/step - loss: 0.7903 - acc: 0.7417\n",
      "Epoch 270/500\n",
      "120/120 [==============================] - 0s 112us/step - loss: 0.7886 - acc: 0.7333\n",
      "Epoch 271/500\n",
      "120/120 [==============================] - 0s 107us/step - loss: 0.7863 - acc: 0.7333\n",
      "Epoch 272/500\n",
      "120/120 [==============================] - 0s 105us/step - loss: 0.7842 - acc: 0.7333\n",
      "Epoch 273/500\n",
      "120/120 [==============================] - 0s 104us/step - loss: 0.7822 - acc: 0.7333\n",
      "Epoch 274/500\n",
      "120/120 [==============================] - 0s 108us/step - loss: 0.7800 - acc: 0.7417\n",
      "Epoch 275/500\n",
      "120/120 [==============================] - 0s 103us/step - loss: 0.7780 - acc: 0.7500\n",
      "Epoch 276/500\n",
      "120/120 [==============================] - 0s 114us/step - loss: 0.7759 - acc: 0.7417\n",
      "Epoch 277/500\n",
      "120/120 [==============================] - 0s 95us/step - loss: 0.7738 - acc: 0.7417\n",
      "Epoch 278/500\n",
      "120/120 [==============================] - 0s 98us/step - loss: 0.7717 - acc: 0.7500\n",
      "Epoch 279/500\n",
      "120/120 [==============================] - 0s 96us/step - loss: 0.7696 - acc: 0.7417\n",
      "Epoch 280/500\n",
      "120/120 [==============================] - 0s 91us/step - loss: 0.7676 - acc: 0.7417\n",
      "Epoch 281/500\n",
      "120/120 [==============================] - 0s 86us/step - loss: 0.7655 - acc: 0.7417\n",
      "Epoch 282/500\n",
      "120/120 [==============================] - 0s 83us/step - loss: 0.7635 - acc: 0.7417\n",
      "Epoch 283/500\n",
      "120/120 [==============================] - 0s 85us/step - loss: 0.7613 - acc: 0.7417\n",
      "Epoch 284/500\n",
      "120/120 [==============================] - 0s 79us/step - loss: 0.7592 - acc: 0.7500\n",
      "Epoch 285/500\n",
      "120/120 [==============================] - 0s 84us/step - loss: 0.7575 - acc: 0.7417\n",
      "Epoch 286/500\n",
      "120/120 [==============================] - 0s 82us/step - loss: 0.7551 - acc: 0.7500\n",
      "Epoch 287/500\n",
      "120/120 [==============================] - 0s 75us/step - loss: 0.7528 - acc: 0.7583\n",
      "Epoch 288/500\n",
      "120/120 [==============================] - 0s 78us/step - loss: 0.7508 - acc: 0.7583\n",
      "Epoch 289/500\n",
      "120/120 [==============================] - 0s 81us/step - loss: 0.7486 - acc: 0.7583\n",
      "Epoch 290/500\n",
      "120/120 [==============================] - 0s 84us/step - loss: 0.7464 - acc: 0.7583\n",
      "Epoch 291/500\n",
      "120/120 [==============================] - 0s 82us/step - loss: 0.7444 - acc: 0.7583\n",
      "Epoch 292/500\n",
      "120/120 [==============================] - 0s 81us/step - loss: 0.7423 - acc: 0.7500\n",
      "Epoch 293/500\n",
      "120/120 [==============================] - 0s 89us/step - loss: 0.7402 - acc: 0.7500\n",
      "Epoch 294/500\n",
      "120/120 [==============================] - 0s 115us/step - loss: 0.7383 - acc: 0.7500\n",
      "Epoch 295/500\n",
      "120/120 [==============================] - 0s 89us/step - loss: 0.7361 - acc: 0.7583\n",
      "Epoch 296/500\n",
      "120/120 [==============================] - 0s 104us/step - loss: 0.7341 - acc: 0.7583\n",
      "Epoch 297/500\n",
      "120/120 [==============================] - 0s 97us/step - loss: 0.7321 - acc: 0.7583\n",
      "Epoch 298/500\n",
      "120/120 [==============================] - 0s 98us/step - loss: 0.7303 - acc: 0.7583\n",
      "Epoch 299/500\n",
      "120/120 [==============================] - 0s 96us/step - loss: 0.7282 - acc: 0.7583\n",
      "Epoch 300/500\n",
      "120/120 [==============================] - 0s 110us/step - loss: 0.7264 - acc: 0.7583\n",
      "Epoch 301/500\n",
      "120/120 [==============================] - 0s 105us/step - loss: 0.7247 - acc: 0.7583\n",
      "Epoch 302/500\n",
      "120/120 [==============================] - 0s 96us/step - loss: 0.7228 - acc: 0.7583\n",
      "Epoch 303/500\n",
      "120/120 [==============================] - 0s 94us/step - loss: 0.7213 - acc: 0.7583\n",
      "Epoch 304/500\n",
      "120/120 [==============================] - 0s 79us/step - loss: 0.7190 - acc: 0.7583\n",
      "Epoch 305/500\n",
      "120/120 [==============================] - 0s 74us/step - loss: 0.7171 - acc: 0.7583\n",
      "Epoch 306/500\n",
      "120/120 [==============================] - 0s 77us/step - loss: 0.7159 - acc: 0.7500\n",
      "Epoch 307/500\n",
      "120/120 [==============================] - 0s 74us/step - loss: 0.7140 - acc: 0.7500\n",
      "Epoch 308/500\n",
      "120/120 [==============================] - 0s 67us/step - loss: 0.7118 - acc: 0.7583\n",
      "Epoch 309/500\n",
      "120/120 [==============================] - 0s 72us/step - loss: 0.7103 - acc: 0.7583\n",
      "Epoch 310/500\n",
      "120/120 [==============================] - 0s 71us/step - loss: 0.7084 - acc: 0.7583\n",
      "Epoch 311/500\n",
      "120/120 [==============================] - 0s 75us/step - loss: 0.7067 - acc: 0.7583\n",
      "Epoch 312/500\n",
      "120/120 [==============================] - 0s 77us/step - loss: 0.7051 - acc: 0.7583\n",
      "Epoch 313/500\n",
      "120/120 [==============================] - 0s 72us/step - loss: 0.7033 - acc: 0.7583\n",
      "Epoch 314/500\n",
      "120/120 [==============================] - 0s 79us/step - loss: 0.7015 - acc: 0.7583\n",
      "Epoch 315/500\n",
      "120/120 [==============================] - 0s 74us/step - loss: 0.6999 - acc: 0.7583\n",
      "Epoch 316/500\n",
      "120/120 [==============================] - 0s 73us/step - loss: 0.6982 - acc: 0.7583\n",
      "Epoch 317/500\n",
      "120/120 [==============================] - 0s 99us/step - loss: 0.6966 - acc: 0.7583\n",
      "Epoch 318/500\n",
      "120/120 [==============================] - 0s 97us/step - loss: 0.6950 - acc: 0.7583\n",
      "Epoch 319/500\n",
      "120/120 [==============================] - 0s 81us/step - loss: 0.6933 - acc: 0.7583\n",
      "Epoch 320/500\n",
      "120/120 [==============================] - 0s 77us/step - loss: 0.6917 - acc: 0.7583\n",
      "Epoch 321/500\n",
      "120/120 [==============================] - 0s 77us/step - loss: 0.6900 - acc: 0.7583\n",
      "Epoch 322/500\n",
      "120/120 [==============================] - 0s 80us/step - loss: 0.6886 - acc: 0.7583\n",
      "Epoch 323/500\n",
      "120/120 [==============================] - 0s 71us/step - loss: 0.6869 - acc: 0.7583\n",
      "Epoch 324/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 0s 85us/step - loss: 0.6855 - acc: 0.7583\n",
      "Epoch 325/500\n",
      "120/120 [==============================] - 0s 80us/step - loss: 0.6838 - acc: 0.7583\n",
      "Epoch 326/500\n",
      "120/120 [==============================] - 0s 80us/step - loss: 0.6821 - acc: 0.7583\n",
      "Epoch 327/500\n",
      "120/120 [==============================] - 0s 81us/step - loss: 0.6806 - acc: 0.7583\n",
      "Epoch 328/500\n",
      "120/120 [==============================] - 0s 82us/step - loss: 0.6790 - acc: 0.7583\n",
      "Epoch 329/500\n",
      "120/120 [==============================] - 0s 63us/step - loss: 0.6775 - acc: 0.7667\n",
      "Epoch 330/500\n",
      "120/120 [==============================] - 0s 89us/step - loss: 0.6760 - acc: 0.7667\n",
      "Epoch 331/500\n",
      "120/120 [==============================] - 0s 97us/step - loss: 0.6747 - acc: 0.7583\n",
      "Epoch 332/500\n",
      "120/120 [==============================] - 0s 91us/step - loss: 0.6730 - acc: 0.7833\n",
      "Epoch 333/500\n",
      "120/120 [==============================] - 0s 96us/step - loss: 0.6714 - acc: 0.7750\n",
      "Epoch 334/500\n",
      "120/120 [==============================] - 0s 92us/step - loss: 0.6700 - acc: 0.7750\n",
      "Epoch 335/500\n",
      "120/120 [==============================] - 0s 97us/step - loss: 0.6684 - acc: 0.7750\n",
      "Epoch 336/500\n",
      "120/120 [==============================] - 0s 95us/step - loss: 0.6669 - acc: 0.7833\n",
      "Epoch 337/500\n",
      "120/120 [==============================] - 0s 125us/step - loss: 0.6657 - acc: 0.7833\n",
      "Epoch 338/500\n",
      "120/120 [==============================] - 0s 111us/step - loss: 0.6639 - acc: 0.7833\n",
      "Epoch 339/500\n",
      "120/120 [==============================] - 0s 122us/step - loss: 0.6625 - acc: 0.7750\n",
      "Epoch 340/500\n",
      "120/120 [==============================] - 0s 105us/step - loss: 0.6610 - acc: 0.7833\n",
      "Epoch 341/500\n",
      "120/120 [==============================] - 0s 109us/step - loss: 0.6597 - acc: 0.7833\n",
      "Epoch 342/500\n",
      "120/120 [==============================] - 0s 90us/step - loss: 0.6580 - acc: 0.7833\n",
      "Epoch 343/500\n",
      "120/120 [==============================] - 0s 97us/step - loss: 0.6566 - acc: 0.7917\n",
      "Epoch 344/500\n",
      "120/120 [==============================] - 0s 100us/step - loss: 0.6556 - acc: 0.7833\n",
      "Epoch 345/500\n",
      "120/120 [==============================] - 0s 83us/step - loss: 0.6537 - acc: 0.7833\n",
      "Epoch 346/500\n",
      "120/120 [==============================] - 0s 84us/step - loss: 0.6523 - acc: 0.7833\n",
      "Epoch 347/500\n",
      "120/120 [==============================] - 0s 81us/step - loss: 0.6509 - acc: 0.7917\n",
      "Epoch 348/500\n",
      "120/120 [==============================] - 0s 71us/step - loss: 0.6496 - acc: 0.7917\n",
      "Epoch 349/500\n",
      "120/120 [==============================] - 0s 78us/step - loss: 0.6482 - acc: 0.8000\n",
      "Epoch 350/500\n",
      "120/120 [==============================] - 0s 82us/step - loss: 0.6466 - acc: 0.7917\n",
      "Epoch 351/500\n",
      "120/120 [==============================] - 0s 77us/step - loss: 0.6454 - acc: 0.7917\n",
      "Epoch 352/500\n",
      "120/120 [==============================] - 0s 81us/step - loss: 0.6439 - acc: 0.7917\n",
      "Epoch 353/500\n",
      "120/120 [==============================] - 0s 78us/step - loss: 0.6427 - acc: 0.7833\n",
      "Epoch 354/500\n",
      "120/120 [==============================] - 0s 78us/step - loss: 0.6412 - acc: 0.8000\n",
      "Epoch 355/500\n",
      "120/120 [==============================] - 0s 82us/step - loss: 0.6398 - acc: 0.7917\n",
      "Epoch 356/500\n",
      "120/120 [==============================] - 0s 103us/step - loss: 0.6386 - acc: 0.8000\n",
      "Epoch 357/500\n",
      "120/120 [==============================] - 0s 84us/step - loss: 0.6371 - acc: 0.7917\n",
      "Epoch 358/500\n",
      "120/120 [==============================] - 0s 79us/step - loss: 0.6358 - acc: 0.8000\n",
      "Epoch 359/500\n",
      "120/120 [==============================] - 0s 89us/step - loss: 0.6345 - acc: 0.8083\n",
      "Epoch 360/500\n",
      "120/120 [==============================] - 0s 79us/step - loss: 0.6333 - acc: 0.8083\n",
      "Epoch 361/500\n",
      "120/120 [==============================] - 0s 69us/step - loss: 0.6318 - acc: 0.8083\n",
      "Epoch 362/500\n",
      "120/120 [==============================] - 0s 83us/step - loss: 0.6306 - acc: 0.8083\n",
      "Epoch 363/500\n",
      "120/120 [==============================] - 0s 78us/step - loss: 0.6293 - acc: 0.8083\n",
      "Epoch 364/500\n",
      "120/120 [==============================] - 0s 79us/step - loss: 0.6280 - acc: 0.8167\n",
      "Epoch 365/500\n",
      "120/120 [==============================] - 0s 85us/step - loss: 0.6266 - acc: 0.8167\n",
      "Epoch 366/500\n",
      "120/120 [==============================] - 0s 80us/step - loss: 0.6254 - acc: 0.8167\n",
      "Epoch 367/500\n",
      "120/120 [==============================] - 0s 85us/step - loss: 0.6243 - acc: 0.8167\n",
      "Epoch 368/500\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.6377 - acc: 0.812 - 0s 77us/step - loss: 0.6229 - acc: 0.8167\n",
      "Epoch 369/500\n",
      "120/120 [==============================] - 0s 86us/step - loss: 0.6216 - acc: 0.8167\n",
      "Epoch 370/500\n",
      "120/120 [==============================] - 0s 80us/step - loss: 0.6204 - acc: 0.8167\n",
      "Epoch 371/500\n",
      "120/120 [==============================] - 0s 82us/step - loss: 0.6191 - acc: 0.8167\n",
      "Epoch 372/500\n",
      "120/120 [==============================] - 0s 78us/step - loss: 0.6180 - acc: 0.8167\n",
      "Epoch 373/500\n",
      "120/120 [==============================] - 0s 82us/step - loss: 0.6168 - acc: 0.8167\n",
      "Epoch 374/500\n",
      "120/120 [==============================] - 0s 84us/step - loss: 0.6162 - acc: 0.8167\n",
      "Epoch 375/500\n",
      "120/120 [==============================] - 0s 83us/step - loss: 0.6142 - acc: 0.8250\n",
      "Epoch 376/500\n",
      "120/120 [==============================] - 0s 81us/step - loss: 0.6129 - acc: 0.8250\n",
      "Epoch 377/500\n",
      "120/120 [==============================] - 0s 80us/step - loss: 0.6117 - acc: 0.8167\n",
      "Epoch 378/500\n",
      "120/120 [==============================] - 0s 80us/step - loss: 0.6106 - acc: 0.8167\n",
      "Epoch 379/500\n",
      "120/120 [==============================] - 0s 77us/step - loss: 0.6098 - acc: 0.8083\n",
      "Epoch 380/500\n",
      "120/120 [==============================] - 0s 82us/step - loss: 0.6085 - acc: 0.8083\n",
      "Epoch 381/500\n",
      "120/120 [==============================] - 0s 77us/step - loss: 0.6071 - acc: 0.8167\n",
      "Epoch 382/500\n",
      "120/120 [==============================] - 0s 76us/step - loss: 0.6058 - acc: 0.8250\n",
      "Epoch 383/500\n",
      "120/120 [==============================] - 0s 72us/step - loss: 0.6047 - acc: 0.8250\n",
      "Epoch 384/500\n",
      "120/120 [==============================] - 0s 73us/step - loss: 0.6034 - acc: 0.8250\n",
      "Epoch 385/500\n",
      "120/120 [==============================] - 0s 74us/step - loss: 0.6023 - acc: 0.8250\n",
      "Epoch 386/500\n",
      "120/120 [==============================] - 0s 71us/step - loss: 0.6011 - acc: 0.8250\n",
      "Epoch 387/500\n",
      "120/120 [==============================] - 0s 72us/step - loss: 0.6000 - acc: 0.8333\n",
      "Epoch 388/500\n",
      "120/120 [==============================] - 0s 74us/step - loss: 0.5988 - acc: 0.8333\n",
      "Epoch 389/500\n",
      "120/120 [==============================] - 0s 71us/step - loss: 0.5983 - acc: 0.8250\n",
      "Epoch 390/500\n",
      "120/120 [==============================] - 0s 74us/step - loss: 0.5967 - acc: 0.8250\n",
      "Epoch 391/500\n",
      "120/120 [==============================] - 0s 75us/step - loss: 0.5959 - acc: 0.8250\n",
      "Epoch 392/500\n",
      "120/120 [==============================] - 0s 71us/step - loss: 0.5942 - acc: 0.8333\n",
      "Epoch 393/500\n",
      "120/120 [==============================] - 0s 73us/step - loss: 0.5934 - acc: 0.8250\n",
      "Epoch 394/500\n",
      "120/120 [==============================] - 0s 76us/step - loss: 0.5922 - acc: 0.8250\n",
      "Epoch 395/500\n",
      "120/120 [==============================] - 0s 82us/step - loss: 0.5911 - acc: 0.8333\n",
      "Epoch 396/500\n",
      "120/120 [==============================] - 0s 86us/step - loss: 0.5897 - acc: 0.8333\n",
      "Epoch 397/500\n",
      "120/120 [==============================] - 0s 77us/step - loss: 0.5886 - acc: 0.8250\n",
      "Epoch 398/500\n",
      "120/120 [==============================] - 0s 77us/step - loss: 0.5876 - acc: 0.8250\n",
      "Epoch 399/500\n",
      "120/120 [==============================] - 0s 75us/step - loss: 0.5870 - acc: 0.8250\n",
      "Epoch 400/500\n",
      "120/120 [==============================] - 0s 79us/step - loss: 0.5859 - acc: 0.8250\n",
      "Epoch 401/500\n",
      "120/120 [==============================] - 0s 80us/step - loss: 0.5843 - acc: 0.8250\n",
      "Epoch 402/500\n",
      "120/120 [==============================] - 0s 75us/step - loss: 0.5834 - acc: 0.8333\n",
      "Epoch 403/500\n",
      "120/120 [==============================] - 0s 78us/step - loss: 0.5824 - acc: 0.8333\n",
      "Epoch 404/500\n",
      "120/120 [==============================] - 0s 76us/step - loss: 0.5816 - acc: 0.8250\n",
      "Epoch 405/500\n",
      "120/120 [==============================] - 0s 78us/step - loss: 0.5802 - acc: 0.8250\n",
      "Epoch 406/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 0s 74us/step - loss: 0.5790 - acc: 0.8250\n",
      "Epoch 407/500\n",
      "120/120 [==============================] - 0s 77us/step - loss: 0.5781 - acc: 0.8250\n",
      "Epoch 408/500\n",
      "120/120 [==============================] - 0s 74us/step - loss: 0.5771 - acc: 0.8250\n",
      "Epoch 409/500\n",
      "120/120 [==============================] - 0s 75us/step - loss: 0.5759 - acc: 0.8333\n",
      "Epoch 410/500\n",
      "120/120 [==============================] - 0s 68us/step - loss: 0.5750 - acc: 0.8333\n",
      "Epoch 411/500\n",
      "120/120 [==============================] - 0s 75us/step - loss: 0.5739 - acc: 0.8333\n",
      "Epoch 412/500\n",
      "120/120 [==============================] - 0s 65us/step - loss: 0.5729 - acc: 0.8250\n",
      "Epoch 413/500\n",
      "120/120 [==============================] - 0s 64us/step - loss: 0.5720 - acc: 0.8250\n",
      "Epoch 414/500\n",
      "120/120 [==============================] - 0s 68us/step - loss: 0.5711 - acc: 0.8250\n",
      "Epoch 415/500\n",
      "120/120 [==============================] - 0s 70us/step - loss: 0.5698 - acc: 0.8333\n",
      "Epoch 416/500\n",
      "120/120 [==============================] - 0s 73us/step - loss: 0.5688 - acc: 0.8333\n",
      "Epoch 417/500\n",
      "120/120 [==============================] - 0s 73us/step - loss: 0.5680 - acc: 0.8333\n",
      "Epoch 418/500\n",
      "120/120 [==============================] - 0s 74us/step - loss: 0.5669 - acc: 0.8333\n",
      "Epoch 419/500\n",
      "120/120 [==============================] - 0s 77us/step - loss: 0.5660 - acc: 0.8333\n",
      "Epoch 420/500\n",
      "120/120 [==============================] - 0s 72us/step - loss: 0.5652 - acc: 0.8333\n",
      "Epoch 421/500\n",
      "120/120 [==============================] - 0s 70us/step - loss: 0.5639 - acc: 0.8333\n",
      "Epoch 422/500\n",
      "120/120 [==============================] - 0s 68us/step - loss: 0.5629 - acc: 0.8333\n",
      "Epoch 423/500\n",
      "120/120 [==============================] - 0s 67us/step - loss: 0.5622 - acc: 0.8417\n",
      "Epoch 424/500\n",
      "120/120 [==============================] - 0s 70us/step - loss: 0.5613 - acc: 0.8333\n",
      "Epoch 425/500\n",
      "120/120 [==============================] - 0s 80us/step - loss: 0.5600 - acc: 0.8333\n",
      "Epoch 426/500\n",
      "120/120 [==============================] - 0s 85us/step - loss: 0.5590 - acc: 0.8333\n",
      "Epoch 427/500\n",
      "120/120 [==============================] - 0s 78us/step - loss: 0.5582 - acc: 0.8333\n",
      "Epoch 428/500\n",
      "120/120 [==============================] - 0s 68us/step - loss: 0.5571 - acc: 0.8333\n",
      "Epoch 429/500\n",
      "120/120 [==============================] - 0s 72us/step - loss: 0.5560 - acc: 0.8333\n",
      "Epoch 430/500\n",
      "120/120 [==============================] - 0s 71us/step - loss: 0.5552 - acc: 0.8333\n",
      "Epoch 431/500\n",
      "120/120 [==============================] - 0s 76us/step - loss: 0.5542 - acc: 0.8500\n",
      "Epoch 432/500\n",
      "120/120 [==============================] - 0s 77us/step - loss: 0.5533 - acc: 0.8500\n",
      "Epoch 433/500\n",
      "120/120 [==============================] - 0s 76us/step - loss: 0.5524 - acc: 0.8500\n",
      "Epoch 434/500\n",
      "120/120 [==============================] - 0s 75us/step - loss: 0.5514 - acc: 0.8500\n",
      "Epoch 435/500\n",
      "120/120 [==============================] - 0s 71us/step - loss: 0.5507 - acc: 0.8583\n",
      "Epoch 436/500\n",
      "120/120 [==============================] - 0s 68us/step - loss: 0.5495 - acc: 0.8583\n",
      "Epoch 437/500\n",
      "120/120 [==============================] - 0s 71us/step - loss: 0.5487 - acc: 0.8667\n",
      "Epoch 438/500\n",
      "120/120 [==============================] - 0s 72us/step - loss: 0.5479 - acc: 0.8583\n",
      "Epoch 439/500\n",
      "120/120 [==============================] - 0s 73us/step - loss: 0.5468 - acc: 0.8583\n",
      "Epoch 440/500\n",
      "120/120 [==============================] - 0s 68us/step - loss: 0.5458 - acc: 0.8583\n",
      "Epoch 441/500\n",
      "120/120 [==============================] - 0s 73us/step - loss: 0.5452 - acc: 0.8417\n",
      "Epoch 442/500\n",
      "120/120 [==============================] - 0s 71us/step - loss: 0.5441 - acc: 0.8500\n",
      "Epoch 443/500\n",
      "120/120 [==============================] - 0s 83us/step - loss: 0.5431 - acc: 0.8500\n",
      "Epoch 444/500\n",
      "120/120 [==============================] - 0s 85us/step - loss: 0.5422 - acc: 0.8500\n",
      "Epoch 445/500\n",
      "120/120 [==============================] - 0s 77us/step - loss: 0.5413 - acc: 0.8500\n",
      "Epoch 446/500\n",
      "120/120 [==============================] - 0s 75us/step - loss: 0.5405 - acc: 0.8500\n",
      "Epoch 447/500\n",
      "120/120 [==============================] - 0s 71us/step - loss: 0.5395 - acc: 0.8583\n",
      "Epoch 448/500\n",
      "120/120 [==============================] - 0s 75us/step - loss: 0.5388 - acc: 0.8667\n",
      "Epoch 449/500\n",
      "120/120 [==============================] - 0s 75us/step - loss: 0.5378 - acc: 0.8667\n",
      "Epoch 450/500\n",
      "120/120 [==============================] - 0s 79us/step - loss: 0.5369 - acc: 0.8667\n",
      "Epoch 451/500\n",
      "120/120 [==============================] - 0s 72us/step - loss: 0.5360 - acc: 0.8583\n",
      "Epoch 452/500\n",
      "120/120 [==============================] - 0s 74us/step - loss: 0.5351 - acc: 0.8583\n",
      "Epoch 453/500\n",
      "120/120 [==============================] - 0s 70us/step - loss: 0.5346 - acc: 0.8500\n",
      "Epoch 454/500\n",
      "120/120 [==============================] - 0s 73us/step - loss: 0.5335 - acc: 0.8500\n",
      "Epoch 455/500\n",
      "120/120 [==============================] - 0s 73us/step - loss: 0.5328 - acc: 0.8750\n",
      "Epoch 456/500\n",
      "120/120 [==============================] - 0s 74us/step - loss: 0.5316 - acc: 0.8750\n",
      "Epoch 457/500\n",
      "120/120 [==============================] - 0s 73us/step - loss: 0.5308 - acc: 0.8750\n",
      "Epoch 458/500\n",
      "120/120 [==============================] - 0s 76us/step - loss: 0.5299 - acc: 0.8667\n",
      "Epoch 459/500\n",
      "120/120 [==============================] - 0s 73us/step - loss: 0.5290 - acc: 0.8667\n",
      "Epoch 460/500\n",
      "120/120 [==============================] - 0s 73us/step - loss: 0.5282 - acc: 0.8667\n",
      "Epoch 461/500\n",
      "120/120 [==============================] - 0s 69us/step - loss: 0.5273 - acc: 0.8583\n",
      "Epoch 462/500\n",
      "120/120 [==============================] - 0s 76us/step - loss: 0.5264 - acc: 0.8667\n",
      "Epoch 463/500\n",
      "120/120 [==============================] - 0s 73us/step - loss: 0.5255 - acc: 0.8667\n",
      "Epoch 464/500\n",
      "120/120 [==============================] - 0s 69us/step - loss: 0.5247 - acc: 0.8667\n",
      "Epoch 465/500\n",
      "120/120 [==============================] - 0s 70us/step - loss: 0.5238 - acc: 0.8667\n",
      "Epoch 466/500\n",
      "120/120 [==============================] - 0s 73us/step - loss: 0.5230 - acc: 0.8750\n",
      "Epoch 467/500\n",
      "120/120 [==============================] - 0s 71us/step - loss: 0.5220 - acc: 0.8750\n",
      "Epoch 468/500\n",
      "120/120 [==============================] - 0s 74us/step - loss: 0.5211 - acc: 0.8750\n",
      "Epoch 469/500\n",
      "120/120 [==============================] - 0s 71us/step - loss: 0.5205 - acc: 0.8750\n",
      "Epoch 470/500\n",
      "120/120 [==============================] - 0s 65us/step - loss: 0.5194 - acc: 0.8750\n",
      "Epoch 471/500\n",
      "120/120 [==============================] - 0s 78us/step - loss: 0.5185 - acc: 0.8750\n",
      "Epoch 472/500\n",
      "120/120 [==============================] - 0s 71us/step - loss: 0.5177 - acc: 0.8750\n",
      "Epoch 473/500\n",
      "120/120 [==============================] - 0s 71us/step - loss: 0.5169 - acc: 0.8750\n",
      "Epoch 474/500\n",
      "120/120 [==============================] - 0s 80us/step - loss: 0.5158 - acc: 0.8750\n",
      "Epoch 475/500\n",
      "120/120 [==============================] - 0s 79us/step - loss: 0.5150 - acc: 0.8750\n",
      "Epoch 476/500\n",
      "120/120 [==============================] - 0s 75us/step - loss: 0.5142 - acc: 0.8750\n",
      "Epoch 477/500\n",
      "120/120 [==============================] - 0s 74us/step - loss: 0.5135 - acc: 0.8750\n",
      "Epoch 478/500\n",
      "120/120 [==============================] - 0s 72us/step - loss: 0.5124 - acc: 0.8750\n",
      "Epoch 479/500\n",
      "120/120 [==============================] - 0s 69us/step - loss: 0.5115 - acc: 0.8750\n",
      "Epoch 480/500\n",
      "120/120 [==============================] - 0s 70us/step - loss: 0.5107 - acc: 0.8750\n",
      "Epoch 481/500\n",
      "120/120 [==============================] - 0s 74us/step - loss: 0.5097 - acc: 0.8750\n",
      "Epoch 482/500\n",
      "120/120 [==============================] - 0s 74us/step - loss: 0.5089 - acc: 0.8750\n",
      "Epoch 483/500\n",
      "120/120 [==============================] - 0s 73us/step - loss: 0.5080 - acc: 0.8750\n",
      "Epoch 484/500\n",
      "120/120 [==============================] - 0s 69us/step - loss: 0.5069 - acc: 0.8750\n",
      "Epoch 485/500\n",
      "120/120 [==============================] - 0s 72us/step - loss: 0.5066 - acc: 0.8917\n",
      "Epoch 486/500\n",
      "120/120 [==============================] - 0s 73us/step - loss: 0.5050 - acc: 0.8833\n",
      "Epoch 487/500\n",
      "120/120 [==============================] - 0s 70us/step - loss: 0.5046 - acc: 0.8833\n",
      "Epoch 488/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 0s 71us/step - loss: 0.5030 - acc: 0.9000\n",
      "Epoch 489/500\n",
      "120/120 [==============================] - 0s 71us/step - loss: 0.5020 - acc: 0.8917\n",
      "Epoch 490/500\n",
      "120/120 [==============================] - 0s 81us/step - loss: 0.5015 - acc: 0.8917\n",
      "Epoch 491/500\n",
      "120/120 [==============================] - 0s 74us/step - loss: 0.4999 - acc: 0.8917\n",
      "Epoch 492/500\n",
      "120/120 [==============================] - 0s 65us/step - loss: 0.4991 - acc: 0.8917\n",
      "Epoch 493/500\n",
      "120/120 [==============================] - 0s 66us/step - loss: 0.4978 - acc: 0.8917\n",
      "Epoch 494/500\n",
      "120/120 [==============================] - 0s 76us/step - loss: 0.4966 - acc: 0.9000\n",
      "Epoch 495/500\n",
      "120/120 [==============================] - 0s 76us/step - loss: 0.4958 - acc: 0.9000\n",
      "Epoch 496/500\n",
      "120/120 [==============================] - 0s 68us/step - loss: 0.4944 - acc: 0.9000\n",
      "Epoch 497/500\n",
      "120/120 [==============================] - 0s 71us/step - loss: 0.4933 - acc: 0.9000\n",
      "Epoch 498/500\n",
      "120/120 [==============================] - 0s 75us/step - loss: 0.4922 - acc: 0.8917\n",
      "Epoch 499/500\n",
      "120/120 [==============================] - 0s 67us/step - loss: 0.4913 - acc: 0.9000\n",
      "Epoch 500/500\n",
      "120/120 [==============================] - 0s 69us/step - loss: 0.4900 - acc: 0.9000\n",
      "{'batch_size': 32, 'epochs': 500, 'steps': None, 'samples': 120, 'verbose': 1, 'do_validation': False, 'metrics': ['loss', 'acc']}\n",
      "{'loss': [2.9504690647125242, 2.83807635307312, 2.7302477598190307, 2.6217912673950194, 2.51987509727478, 2.4279189427693684, 2.338833777109782, 2.251206715901693, 2.172756878534953, 2.098075286547343, 2.0302649259567263, 1.9622806390126546, 1.9029267390569051, 1.8516275723775228, 1.7944780111312866, 1.7489475806554158, 1.7059051195780437, 1.6652645190556845, 1.6268022537231446, 1.5905790249506633, 1.558834171295166, 1.528305427233378, 1.5003446022669473, 1.4723780552546184, 1.4469831784566243, 1.4245498577753704, 1.4005588610967001, 1.3795087178548178, 1.360702395439148, 1.342171573638916, 1.3248104890187582, 1.3070918718973796, 1.2929148912429809, 1.278137747446696, 1.2641169627507527, 1.251431401570638, 1.2405940850575765, 1.2269469896952312, 1.217097282409668, 1.2073960383733113, 1.1983320871988932, 1.1890899578730265, 1.1809046665827434, 1.1736641963322958, 1.1668328841527302, 1.1595049619674682, 1.15360848903656, 1.147488816579183, 1.142598565419515, 1.1372400363286337, 1.1322330077489218, 1.1275883913040161, 1.1239318688710531, 1.1199895143508911, 1.1157532294591268, 1.1125142733256022, 1.1091551224390666, 1.1059760332107544, 1.1033130327860514, 1.1008731126785278, 1.0976216157277425, 1.0956063270568848, 1.0931702693303427, 1.0910088539123535, 1.089145557085673, 1.0869806289672852, 1.0852352619171142, 1.0832568566004435, 1.0817306756973266, 1.080270489056905, 1.078597617149353, 1.077343742052714, 1.0756471316019693, 1.0740943590799967, 1.072865351041158, 1.0717207590738933, 1.0704517761866252, 1.0692561229070028, 1.0682207028071085, 1.0671083768208822, 1.0657362699508668, 1.0648684899012248, 1.0639479637145997, 1.0627214590708414, 1.0617638905843099, 1.0607351779937744, 1.0596967935562134, 1.0587957143783568, 1.057908574740092, 1.05685240427653, 1.0567142486572265, 1.055169129371643, 1.0541944265365601, 1.0533257325490315, 1.0524343808492025, 1.0515884081522624, 1.050657327969869, 1.0498053391774496, 1.0489465951919557, 1.0481386582056682, 1.0472130060195923, 1.0463961998621623, 1.0456706921259562, 1.044555417696635, 1.0438250382741292, 1.0430442253748575, 1.0419297456741332, 1.0411760330200195, 1.0404237548510233, 1.0394229849179586, 1.0385130325953165, 1.0377270778020222, 1.0367695967356363, 1.0361314773559571, 1.0350879867871603, 1.034104593594869, 1.0331318696339926, 1.032534698645274, 1.0313799222310385, 1.0304346084594727, 1.0295064568519592, 1.0286132136980692, 1.02773384253184, 1.026887559890747, 1.0257334470748902, 1.0248203198115031, 1.023841913541158, 1.0231468200683593, 1.0224177400271097, 1.0210469921429952, 1.0199999650319418, 1.0190904060999553, 1.017993187904358, 1.0170316378275552, 1.0159696578979491, 1.0149810234705607, 1.013892372449239, 1.012928799788157, 1.0118500510851542, 1.0107709089914958, 1.0098470052083333, 1.008706776301066, 1.0076369166374206, 1.0064794381459554, 1.0053979873657226, 1.0044153571128844, 1.0033586661020915, 1.0022440234820047, 1.0010626236597697, 0.9998274087905884, 0.9988608876864116, 0.9975773731867472, 0.9963809649149576, 0.9953062534332275, 0.994040064016978, 0.9928515116373698, 0.9916971842447917, 0.9904712041219076, 0.9892847180366516, 0.9880900144577026, 0.9868179480234782, 0.985652748743693, 0.9841702818870545, 0.9831657608350118, 0.9816153724988301, 0.9803767641385396, 0.9790246526400248, 0.9778957605361939, 0.9763810197512309, 0.9751782695452372, 0.9738676865895589, 0.9725568572680156, 0.971140734354655, 0.9696764469146728, 0.9683159152666728, 0.9669035236040752, 0.9654900987943014, 0.9640109856923421, 0.962567150592804, 0.9612688223520914, 0.9598064144452413, 0.958180550734202, 0.9567174315452576, 0.9552423278490703, 0.9539472063382467, 0.9520758668581645, 0.9505423903465271, 0.9489877502123515, 0.9473495841026306, 0.9458683848381042, 0.9442844231923421, 0.9429940104484558, 0.9409673889478047, 0.9392223517100017, 0.937822182973226, 0.936493448416392, 0.9341617941856384, 0.9325689196586608, 0.930672534306844, 0.9291343847910564, 0.9273462335268656, 0.9254461963971455, 0.9237314065297445, 0.9219624956448873, 0.9201571146647135, 0.9181798815727233, 0.9162999510765075, 0.9145161032676696, 0.9127330144246419, 0.9108281413714091, 0.908751900990804, 0.9068946480751038, 0.9047079245249431, 0.902780004342397, 0.9008442878723144, 0.898843006292979, 0.896986742814382, 0.8946442643801371, 0.8926462650299072, 0.8904448628425599, 0.8883640170097351, 0.8864313880602519, 0.8840674599011739, 0.8820066014925639, 0.8798742771148682, 0.878064489364624, 0.8756658673286438, 0.8737374305725097, 0.8715779304504394, 0.8694199522336324, 0.8673222700754801, 0.8652361114819844, 0.8635207772254944, 0.8610143303871155, 0.8590227961540222, 0.8569908261299133, 0.8548742294311523, 0.853039546807607, 0.8508726755777994, 0.8488603075345357, 0.8468124270439148, 0.8448652863502503, 0.8428197383880616, 0.840813950697581, 0.8388356367746989, 0.8371955831845601, 0.8350823243459066, 0.8330744306246439, 0.8307994842529297, 0.8289081732432048, 0.8268999934196473, 0.8249727368354798, 0.8227938175201416, 0.8207364281018575, 0.8187530676523844, 0.8167529225349426, 0.8146622141202291, 0.8126481572786967, 0.8110857844352722, 0.8085517048835754, 0.8067098935445149, 0.8047673384348552, 0.8026613712310791, 0.8005448659261067, 0.7985194524129232, 0.796551259358724, 0.7943323572476705, 0.7923312306404113, 0.7902777632077534, 0.7886043866475423, 0.7862754940986634, 0.7842039108276367, 0.7821561495463053, 0.7800215204556783, 0.7780480662981669, 0.7758694489796957, 0.7738221645355224, 0.771716562906901, 0.7696273803710938, 0.7675662358601888, 0.7654995123545328, 0.7634509364763896, 0.7612931887308757, 0.7591714024543762, 0.7575128277142843, 0.7551414211591084, 0.7527944087982178, 0.7508310794830322, 0.7485836029052735, 0.7463882486025493, 0.7444041132926941, 0.7422872900962829, 0.7402341643969218, 0.7382640878359477, 0.7361220359802246, 0.7341187278429667, 0.732068411509196, 0.7302605907122294, 0.7281614184379578, 0.7264261404673259, 0.7246870239575703, 0.722775955994924, 0.7213394482930501, 0.7189890901247661, 0.717085595925649, 0.7158669829368591, 0.7139953931172689, 0.7118330359458923, 0.7102873126665751, 0.7083823243776958, 0.7067374428113301, 0.705091408888499, 0.7033097386360169, 0.7015488902727763, 0.6998801906903585, 0.6982087254524231, 0.6966179013252258, 0.6949519356091817, 0.693329918384552, 0.6917186141014099, 0.6900464812914531, 0.6886030793190002, 0.6869436422983806, 0.6854587992032369, 0.6837736090024312, 0.6821406642595927, 0.6805573145548502, 0.6789969086647034, 0.6774844288825989, 0.6760255614916484, 0.6747236768404643, 0.672953204313914, 0.6714385151863098, 0.6699622631072998, 0.6684028744697571, 0.6669497609138488, 0.665662411848704, 0.6639258583386739, 0.6625015576680501, 0.6609903772672018, 0.6596951683362325, 0.658012314637502, 0.6565647800763448, 0.6555539806683858, 0.6537412285804749, 0.6523239572842916, 0.6508649071057637, 0.6496241847674052, 0.6481560707092285, 0.6466331839561462, 0.6454357584317525, 0.6439098954200745, 0.6426507989565532, 0.6412424246470133, 0.6398483792940776, 0.6386044144630432, 0.6371055722236634, 0.635815441608429, 0.6344716548919678, 0.6333088835080465, 0.6318296591440836, 0.6306233684221904, 0.6293235421180725, 0.6279783129692078, 0.6266243616739909, 0.625410266717275, 0.62426331837972, 0.6228582421938579, 0.6215781092643737, 0.6203551808993022, 0.6191299557685852, 0.6179758230845134, 0.6167625586191813, 0.6162364761034648, 0.6141561508178711, 0.6129170576731364, 0.6117081046104431, 0.6105651974678039, 0.6098406672477722, 0.6084795792897543, 0.6071253101030986, 0.6058393438657125, 0.6047234813372294, 0.6033669749895731, 0.6023301998774211, 0.6011295596758525, 0.6000471154848734, 0.5988004803657532, 0.5982682983080546, 0.5967194437980652, 0.5959346095720927, 0.5942261656125386, 0.5933952689170837, 0.5922464013099671, 0.591075336933136, 0.5897195021311442, 0.5886433521906534, 0.5876090884208679, 0.5870112458864848, 0.5858650366465251, 0.5843236486117045, 0.5833967328071594, 0.5823636531829834, 0.5815656065940857, 0.5801708102226257, 0.5790474573771159, 0.5780805905659994, 0.5770615498224895, 0.5759011228879293, 0.5750381628672282, 0.5739281058311463, 0.5728853980700175, 0.5720258831977845, 0.5710626006126404, 0.5697691400845846, 0.5688283244768778, 0.5679678122202555, 0.5668585022290548, 0.5660444060961406, 0.5651528040568033, 0.563907516002655, 0.5629075249036153, 0.5621860067049662, 0.5612834175427754, 0.5599603374799093, 0.5590459704399109, 0.5582341233889262, 0.5571098923683167, 0.5560014883677165, 0.5552096962928772, 0.5542134602864583, 0.5532949964205424, 0.5524382829666138, 0.5513948241869608, 0.5506921609242758, 0.5495182752609253, 0.548654842376709, 0.5478860775629679, 0.5467541178067525, 0.5458460807800293, 0.5451589147249858, 0.5440613905588786, 0.5431436856587728, 0.5422058383623759, 0.5412590305010477, 0.5404865662256877, 0.5394604007403055, 0.5388197620709737, 0.5378138661384583, 0.5368837157885233, 0.5360276103019714, 0.5350799520810445, 0.5345730781555176, 0.5334808548291524, 0.5327837407588959, 0.5316386222839355, 0.5308295289675394, 0.52987672885259, 0.5290023922920227, 0.5281993389129639, 0.527286152044932, 0.5263820211092631, 0.5254997213681539, 0.5246825178464254, 0.5238324960072835, 0.5230308850606282, 0.5220341503620147, 0.5211325685183207, 0.5204508384068807, 0.5194317619005839, 0.518533484141032, 0.5176968812942505, 0.5169165015220643, 0.5158387005329133, 0.5150276362895966, 0.514175162712733, 0.5135163764158884, 0.5124238053957622, 0.5115015029907226, 0.5106913288434346, 0.5097324132919312, 0.5089011629422505, 0.5080352226893107, 0.5069125771522522, 0.5066224098205566, 0.5050463795661926, 0.5046138803164164, 0.5029565374056498, 0.501989996433258, 0.501508762439092, 0.49990185101826984, 0.499052898089091, 0.4978213349978129, 0.49662472208340963, 0.4957742909590403, 0.49442301988601683, 0.4933492958545685, 0.4922020395596822, 0.49128740827242534, 0.4899881939093272], 'acc': [0.3499999980131785, 0.3500000019868215, 0.3500000019868215, 0.35, 0.3499999980131785, 0.35, 0.35, 0.35, 0.3500000019868215, 0.3500000019868215, 0.349999996026357, 0.3499999980131785, 0.3499999980131785, 0.3500000019868215, 0.3500000019868215, 0.35, 0.35, 0.35, 0.3499999980131785, 0.3500000019868215, 0.35, 0.35, 0.3500000019868215, 0.35, 0.3499999980131785, 0.3499999980131785, 0.35, 0.3500000019868215, 0.35, 0.35, 0.35, 0.35, 0.3500000019868215, 0.3499999980131785, 0.3499999980131785, 0.3499999980131785, 0.35, 0.3499999980131785, 0.3500000019868215, 0.3499999980131785, 0.3500000019868215, 0.3500000019868215, 0.35, 0.34999999900658924, 0.3666666656732559, 0.36666666766007744, 0.35833333333333334, 0.3416666666666667, 0.3, 0.2416666676600774, 0.1916666656732559, 0.1416666676600774, 0.14166666567325592, 0.16666666666666666, 0.19166666666666668, 0.2, 0.21666666567325593, 0.23333333333333334, 0.2666666646798452, 0.2916666646798452, 0.3749999980131785, 0.425, 0.4083333333333333, 0.41666666865348817, 0.425, 0.43333333532015483, 0.43333333333333335, 0.4333333293596903, 0.43333333134651186, 0.4249999980131785, 0.425, 0.4166666646798452, 0.4166666646798452, 0.39166666666666666, 0.39166666666666666, 0.3999999980131785, 0.3916666646798452, 0.39166666666666666, 0.39166666865348815, 0.3999999980131785, 0.4083333333333333, 0.400000003973643, 0.4000000019868215, 0.40833333134651184, 0.4, 0.4, 0.3999999980131785, 0.39166666865348815, 0.39166666666666666, 0.39166666865348815, 0.37499999900658926, 0.3749999980131785, 0.3916666646798452, 0.4083333333333333, 0.39166666666666666, 0.39166666666666666, 0.38333333333333336, 0.36666666467984516, 0.36666666467984516, 0.36666666666666664, 0.36666666467984516, 0.3666666686534882, 0.35, 0.3666666686534882, 0.3666666656732559, 0.36666666766007744, 0.36666666467984516, 0.36666666666666664, 0.38333333333333336, 0.38333332935969033, 0.3833333313465118, 0.36666666467984516, 0.36666666666666664, 0.35833333134651185, 0.36666666666666664, 0.36666666467984516, 0.36666666666666664, 0.3583333353201548, 0.3583333353201548, 0.35833333134651185, 0.3583333373069763, 0.3666666686534882, 0.36666666666666664, 0.36666666467984516, 0.36666666666666664, 0.3666666686534882, 0.36666666666666664, 0.35833333333333334, 0.3583333373069763, 0.35833333333333334, 0.35833333134651185, 0.3583333353201548, 0.3499999980131785, 0.3333333353201548, 0.34166666865348816, 0.3583333353201548, 0.35833333134651185, 0.3666666686534882, 0.36666666467984516, 0.36666666766007744, 0.36666666467984516, 0.36666666467984516, 0.3666666686534882, 0.3666666686534882, 0.35833333134651185, 0.3583333353201548, 0.3500000019868215, 0.33333333134651183, 0.3333333333333333, 0.3499999980131785, 0.36666666666666664, 0.3666666686534882, 0.36666666467984516, 0.36666666666666664, 0.36666666467984516, 0.3666666686534882, 0.36666666467984516, 0.36666666467984516, 0.36666666666666664, 0.36666666467984516, 0.3666666686534882, 0.375, 0.3750000019868215, 0.375, 0.36666666467984516, 0.36666666666666664, 0.35833333134651185, 0.3666666686534882, 0.36666666666666664, 0.35833333134651185, 0.35833332935969037, 0.3583333353201548, 0.36666666666666664, 0.3666666686534882, 0.3749999980131785, 0.3750000019868215, 0.3750000019868215, 0.375, 0.36666666666666664, 0.38333333532015484, 0.38333333333333336, 0.38333333532015484, 0.3833333313465118, 0.38333333333333336, 0.36666666666666664, 0.36666666666666664, 0.3583333353201548, 0.35833333333333334, 0.36666666467984516, 0.3666666686534882, 0.3749999980131785, 0.38333333532015484, 0.3749999980131785, 0.3750000019868215, 0.36666666666666664, 0.36666666666666664, 0.3666666656732559, 0.3666666686534882, 0.36666666666666664, 0.3666666686534882, 0.3666666686534882, 0.36666666666666664, 0.3749999980131785, 0.3749999980131785, 0.3750000019868215, 0.375, 0.3833333313465118, 0.39166666666666666, 0.38333333333333336, 0.4000000019868215, 0.4083333333333333, 0.4083333373069763, 0.41666666567325594, 0.4250000019868215, 0.45, 0.45, 0.4666666646798452, 0.48333333333333334, 0.5166666706403097, 0.5583333293596904, 0.6166666706403097, 0.65, 0.6583333293596904, 0.65, 0.649999996026357, 0.6583333373069763, 0.6666666706403096, 0.675, 0.6916666626930237, 0.7, 0.700000003973643, 0.7166666706403096, 0.724999996026357, 0.7416666626930237, 0.7333333333333333, 0.724999996026357, 0.725000003973643, 0.725, 0.724999996026357, 0.724999996026357, 0.7333333333333333, 0.7333333373069764, 0.7333333293596903, 0.7333333333333333, 0.7333333293596903, 0.7333333333333333, 0.7333333293596903, 0.7333333373069764, 0.7333333333333333, 0.7333333293596903, 0.7416666666666667, 0.7333333293596903, 0.7416666666666667, 0.7416666626930237, 0.7416666626930237, 0.7416666706403097, 0.7333333373069764, 0.7416666626930237, 0.7333333293596903, 0.7333333293596903, 0.7333333293596903, 0.7333333333333333, 0.7416666706403097, 0.7333333333333333, 0.7416666706403097, 0.7416666626930237, 0.7333333373069764, 0.7333333333333333, 0.7416666626930237, 0.7333333333333333, 0.7333333373069764, 0.7333333333333333, 0.7333333333333333, 0.7416666626930237, 0.750000003973643, 0.7416666706403097, 0.7416666706403097, 0.750000003973643, 0.7416666666666667, 0.7416666666666667, 0.7416666666666667, 0.7416666626930237, 0.7416666706403097, 0.750000003973643, 0.7416666666666667, 0.75, 0.7583333373069763, 0.7583333373069763, 0.7583333293596903, 0.7583333333333333, 0.7583333333333333, 0.75, 0.75, 0.749999996026357, 0.7583333293596903, 0.7583333293596903, 0.7583333373069763, 0.7583333373069763, 0.7583333293596903, 0.7583333373069763, 0.7583333373069763, 0.7583333333333333, 0.7583333293596903, 0.7583333373069763, 0.7583333293596903, 0.75, 0.750000003973643, 0.7583333293596903, 0.7583333373069763, 0.7583333333333333, 0.7583333293596903, 0.7583333293596903, 0.7583333293596903, 0.7583333293596903, 0.7583333333333333, 0.7583333333333333, 0.7583333373069763, 0.7583333293596903, 0.7583333293596903, 0.7583333333333333, 0.7583333293596903, 0.7583333373069763, 0.7583333333333333, 0.7583333373069763, 0.7583333333333333, 0.7583333373069763, 0.7583333373069763, 0.7583333293596903, 0.7666666626930236, 0.7666666666666667, 0.7583333293596903, 0.7833333373069763, 0.775, 0.775000003973643, 0.774999996026357, 0.7833333333333333, 0.7833333333333333, 0.7833333333333333, 0.774999996026357, 0.7833333373069763, 0.7833333373069763, 0.7833333373069763, 0.7916666666666666, 0.7833333333333333, 0.7833333373069763, 0.7833333373069763, 0.7916666666666666, 0.7916666706403096, 0.799999996026357, 0.7916666626930237, 0.7916666706403096, 0.7916666666666666, 0.7833333293596904, 0.800000003973643, 0.7916666666666666, 0.799999996026357, 0.7916666626930237, 0.8, 0.8083333293596904, 0.8083333293596904, 0.8083333373069763, 0.8083333333333333, 0.8083333293596904, 0.8166666666666667, 0.8166666626930237, 0.8166666706403096, 0.8166666706403096, 0.8166666626930237, 0.8166666666666667, 0.8166666706403096, 0.8166666666666667, 0.8166666706403096, 0.8166666666666667, 0.8166666626930237, 0.825, 0.825, 0.8166666666666667, 0.8166666626930237, 0.8083333373069763, 0.8083333293596904, 0.8166666666666667, 0.825000003973643, 0.825, 0.825000003973643, 0.824999996026357, 0.824999996026357, 0.8333333293596904, 0.8333333373069763, 0.824999996026357, 0.825, 0.825000003973643, 0.8333333373069763, 0.824999996026357, 0.825, 0.8333333293596904, 0.8333333373069763, 0.824999996026357, 0.824999996026357, 0.825, 0.824999996026357, 0.824999996026357, 0.8333333333333334, 0.8333333373069763, 0.824999996026357, 0.824999996026357, 0.824999996026357, 0.824999996026357, 0.824999996026357, 0.8333333373069763, 0.8333333373069763, 0.8333333373069763, 0.824999996026357, 0.825000003973643, 0.825, 0.8333333373069763, 0.8333333293596904, 0.8333333293596904, 0.8333333293596904, 0.8333333333333334, 0.8333333293596904, 0.8333333373069763, 0.8333333373069763, 0.8416666706403096, 0.8333333373069763, 0.8333333333333334, 0.8333333333333334, 0.8333333293596904, 0.8333333373069763, 0.8333333333333334, 0.8333333293596904, 0.85, 0.850000003973643, 0.85, 0.849999996026357, 0.8583333293596903, 0.8583333333333333, 0.8666666626930237, 0.8583333373069764, 0.8583333333333333, 0.8583333373069764, 0.8416666666666667, 0.85, 0.849999996026357, 0.849999996026357, 0.849999996026357, 0.849999996026357, 0.8583333293596903, 0.8666666666666667, 0.8666666666666667, 0.8666666666666667, 0.8583333373069764, 0.8583333293596903, 0.849999996026357, 0.85, 0.875, 0.875, 0.874999996026357, 0.8666666666666667, 0.8666666706403097, 0.8666666666666667, 0.8583333333333333, 0.8666666666666667, 0.8666666626930237, 0.8666666706403097, 0.8666666706403097, 0.875, 0.875000003973643, 0.875, 0.875000003973643, 0.875, 0.874999996026357, 0.875, 0.875, 0.874999996026357, 0.874999996026357, 0.874999996026357, 0.874999996026357, 0.875000003973643, 0.875, 0.874999996026357, 0.875, 0.875000003973643, 0.875000003973643, 0.874999996026357, 0.8916666706403097, 0.8833333293596903, 0.8833333373069763, 0.899999996026357, 0.8916666626930236, 0.8916666706403097, 0.8916666626930236, 0.8916666626930236, 0.8916666706403097, 0.900000003973643, 0.899999996026357, 0.899999996026357, 0.899999996026357, 0.8916666666666667, 0.899999996026357, 0.9]}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 [==============================] - 0s 954us/step\n",
      "acc: 86.66666746139526%\n"
     ]
    }
   ],
   "source": [
    "NN = KerasNeuralNetwork(x_train, y_train, x_test, y_test)\n",
    "NN.run()\n",
    "NN.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
